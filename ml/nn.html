<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Neural Network Basics — Illustrated Cheatsheet</title>
  <!-- Tailwind CSS -->
  <script src="https://cdn.tailwindcss.com"></script>
  <!-- Alpine.js -->
  <script defer src="https://unpkg.com/alpinejs@3.x.x/dist/cdn.min.js"></script>
  <!-- Chart.js (for tiny demo plots) -->
  <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>

  <!-- MathJax (v3) -->
  <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']]
      },
      chtml: {
        // disable MathJax linebreaking entirely
        linebreaks: { automatic: false },
        matchFontHeight: true
      },
      options: {
        // Keep this minimal; MathJax already skips <script>, <style>, etc.
        skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
      },
      svg: { fontCache: 'global' }
    };
  </script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>

  <style>
    :root {
      color-scheme: light;
    }

    html {
      scroll-behavior: smooth;
    }

    .bg-hero {
      background: linear-gradient(120deg, #eef2ff, #f0fdf4, #ecfeff);
      background-size: 200% 200%;
      animation: grad 18s ease infinite;
    }

    @keyframes grad {
      0% {
        background-position: 0% 50%
      }

      50% {
        background-position: 100% 50%
      }

      100% {
        background-position: 0% 50%
      }
    }

    .code {
      font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
    }

    .fade-in {
      animation: fade .25s ease-in;
    }

    @keyframes fade {
      from {
        opacity: .2
      }

      to {
        opacity: 1
      }
    }

    .card {
      backdrop-filter: blur(6px);
    }

    .node {
      filter: drop-shadow(0 2px 2px rgba(0, 0, 0, .06));
    }

    /* Prevent inline MathJax from breaking across lines */
    mjx-container[jax="SVG"][display="inline"] {
      white-space: nowrap;
    }

    /* Make long lines with inline math still usable on small screens */
    .math-nowrap {
      white-space: nowrap;
      overflow-x: auto;
      -webkit-overflow-scrolling: touch;
    }

    /* Optional: keep display equations blocky and not wrapped */
    mjx-container[jax="SVG"][display="true"] {
      display: block;
      overflow-x: auto;
      /* in case a wide display equation exceeds container */
    }
  </style>
</head>

<body class="min-h-screen text-slate-800">

  <!-- Header -->
  <header class="bg-hero">
    <div class="max-w-7xl mx-auto px-6 py-12 lg:py-16">
      <div class="flex flex-col lg:flex-row items-center gap-10">
        <div class="flex-1">
          <h1 class="text-4xl md:text-5xl font-extrabold tracking-tight text-slate-900">
            Neural Network <span class="text-indigo-600">Basics</span> Cheatsheet
          </h1>
          <p class="mt-3 text-lg md:text-xl text-slate-700 max-w-2xl">
            A crisp, single-file reference for feedforward NNs: neurons, activations, losses, optimizers,
            regularization, initialization, metrics, and training tips — with bite-size math and visuals.
          </p>
          <div class="mt-5 flex flex-wrap gap-3">
            <a href="#primer"
              class="px-5 py-3 rounded-xl bg-indigo-600 text-white font-semibold shadow hover:bg-indigo-700">Start
              here</a>
            <a href="#activations"
              class="px-5 py-3 rounded-xl bg-white ring-1 ring-slate-200 shadow-sm font-semibold hover:bg-slate-50">Activations</a>
            <a href="#optimizers"
              class="px-5 py-3 rounded-xl bg-white ring-1 ring-slate-200 shadow-sm font-semibold hover:bg-slate-50">Optimizers</a>
          </div>
          <p class="mt-4 text-sm text-slate-500">Single file • Tailwind + Alpine + Chart.js • MathJax • No build step
          </p>
        </div>
        <div class="flex-1 w-full">
          <div class="bg-white/70 card rounded-2xl p-6 shadow border border-slate-100">
            <canvas id="sparkLoss" height="220"></canvas>
            <p class="mt-3 text-center text-sm text-slate-600">Toy training curves (loss & lr schedule preview).</p>
          </div>
        </div>
      </div>
    </div>
  </header>

  <!-- Primer / Single Neuron -->
  <section id="primer" class="py-12">
    <div class="max-w-7xl mx-auto px-6">
      <div class="mb-8">
        <h2 class="text-3xl font-bold tracking-tight text-slate-900">Single Neuron & Forward Pass</h2>
        <p class="mt-2 text-slate-600 max-w-3xl">
          A neuron computes a weighted sum plus bias then applies a nonlinearity:
          <span>\( z = w\cdot x + b, \quad a = \sigma(z). \)</span>
          Stacking layers yields a universal function approximator; training adjusts <span class="code">W, b</span> to
          minimize a loss.
        </p>
      </div>
      <div class="grid lg:grid-cols-2 gap-6">
        <article class="bg-white border border-slate-200 rounded-2xl p-6 shadow">
          <h3 class="text-xl font-semibold">Worked Example</h3>
          <div class="text-sm leading-7 text-slate-700">
            <span class="code">x = [0.5, −0.3, 0.8]</span><br>
            <span class="code">w = [0.7, −0.4, 0.9]<br>
              <span class="code">b = 0.2</span>
              <span class="code">\( z = 0.7\cdot0.5 + (-0.4)\cdot(-0.3) + 0.9\cdot0.8 + 0.2 = 1.39 \)</span>
              <br>
              <b>Sigmoid output</b><br><span>\( \sigma(1.39) \approx 0.73 \)</span>
          </div>
          <div>
            <svg viewBox="0 0 440 220" class="w-full h-auto">
              <!-- inputs -->
              <g fill="#1e293b" font-size="12" text-anchor="middle">
                <circle cx="60" cy="40" r="16" fill="#eef2ff" stroke="#c7d2fe" />
                <text x="60" y="44">x₁</text>
                <circle cx="60" cy="110" r="16" fill="#eef2ff" stroke="#c7d2fe" />
                <text x="60" y="114">x₂</text>
                <circle cx="60" cy="180" r="16" fill="#eef2ff" stroke="#c7d2fe" />
                <text x="60" y="184">x₃</text>
              </g>
              <!-- neuron -->
              <g>
                <rect x="180" y="75" width="80" height="70" rx="12" fill="#ffffff" stroke="#e2e8f0" />
                <text x="220" y="100" text-anchor="middle" font-size="12" fill="#334155">Σ + b</text>
                <text x="220" y="125" text-anchor="middle" font-size="11" fill="#64748b">z = 1.39</text>
              </g>
              <g>
                <rect x="300" y="75" width="80" height="70" rx="12" fill="#ffffff" stroke="#e2e8f0" />
                <text x="340" y="100" text-anchor="middle" font-size="12" fill="#334155">σ(z)</text>
                <text x="340" y="125" text-anchor="middle" font-size="11" fill="#64748b">0.73</text>
              </g>
              <!-- arrows & weights -->
              <defs>
                <marker id="arrow" markerWidth="6" markerHeight="6" refX="5" refY="3" orient="auto"
                  markerUnits="strokeWidth">
                  <path d="M0,0 L0,6 L6,3 z" fill="#94a3b8" />
                </marker>
              </defs>
              <g stroke="#94a3b8" stroke-width="1" fill="none" marker-end="url(#arrow)" font-size="11" fill="#000000">
                <path d="M76,40 C120,40 140,90 180,110" />
                <text x="130" y="56">w₁=0.7</text>
                <path d="M76,110 C120,110 140,110 180,110" />
                <text x="130" y="100">w₂=−0.4</text>
                <path d="M76,180 C120,180 140,130 180,110" />
                <text x="130" y="170">w₃=0.9</text>
                <path d="M260,110 L300,110" />
              </g>
            </svg>
            <p class="mt-3 text-xs text-slate-500">Each neuron is a weighted sum followed by a non-linear
              transformation.</p>
          </div>
        </article>

        <article class="bg-white border border-slate-200 rounded-2xl p-6 shadow">
          <h3 class="text-xl font-semibold">Feedforward Layer Math</h3>
          <div class="mt-3 text-sm leading-7 text-slate-700 space-y-3">
            <p class="whitespace-nowrap overflow-x-auto">
              Layer <span class="code">ℓ</span>:
              \( z^{(\ell)} = W^{(\ell)} a^{(\ell-1)} + b^{(\ell)}, \quad a^{(\ell)} = \sigma\!\left(z^{(\ell)}\right)
              \)
            </p>
            <p>Backprop (one layer):
              <span>\( \frac{\partial L}{\partial W^{(\ell)}} = \delta^{(\ell)}\, (a^{(\ell-1)})^{\mathsf T}, \)</span>
              <span>\( \text{where} \delta^{(\ell)} = \frac{\partial L}{\partial z^{(\ell)}}. \)</span>
            </p>
            <div class="p-3 rounded-xl bg-slate-50 border border-slate-200 text-xs">
              <div class="font-semibold mb-1">Training loop</div>
              <div class="grid md:grid-cols-4 gap-2">
                <div class="p-2 rounded-lg bg-white border text-center">Forward: <span class="code">X → ŷ</span></div>
                <div class="p-2 rounded-lg bg-white border text-center">Loss: <span class="code">L(y, ŷ)</span></div>
                <div class="p-2 rounded-lg bg-white border text-center">Backward: <span class="code">∇L</span></div>
                <div class="p-2 rounded-lg bg-white border text-center">Update: <span>\( w \leftarrow w - \alpha \nabla
                    L \)</span></div>
              </div>
            </div>
          </div>
        </article>
      </div>
    </div>
  </section>

  <!-- Activations -->
  <section id="activations" class="py-12 bg-slate-50">
    <div class="max-w-7xl mx-auto px-6">
      <h2 class="text-3xl font-bold tracking-tight text-slate-900">Activations</h2>
      <p class="mt-2 text-slate-600 max-w-3xl">Choose ReLU-family for hidden layers by default; use task-specific output
        activations.</p>
      <div class="mt-6 grid md:grid-cols-2 lg:grid-cols-3 gap-4">
        <!-- Cards -->
        <div class="bg-white rounded-2xl shadow p-4 border border-slate-200">
          <div class="text-sm text-slate-500">ReLU</div>
          <div class="text-xl font-semibold">\( \max(0, x) \)</div>
          <div class="text-xs text-slate-500">Range: [0, ∞)</div>
          <canvas class="mt-3 h-28" data-act="relu"></canvas>
        </div>
        <div class="bg-white rounded-2xl shadow p-4 border border-slate-200">
          <div class="text-sm text-slate-500">Leaky ReLU</div>
          <div class="text-xl font-semibold">\( \max(\alpha x, x) \)</div>
          <div class="text-xs text-slate-500">Range: (−∞, ∞)</div>
          <canvas class="mt-3 h-28" data-act="lrelu"></canvas>
        </div>
        <div class="bg-white rounded-2xl shadow p-4 border border-slate-200">
          <div class="text-sm text-slate-500">Sigmoid</div>
          <div class="text-xl font-semibold">\( \sigma(x)=\frac{1}{1+e^{-x}} \)</div>
          <div class="text-xs text-slate-500">Range: (0, 1)</div>
          <canvas class="mt-3 h-28" data-act="sigmoid"></canvas>
        </div>
        <div class="bg-white rounded-2xl shadow p-4 border border-slate-200">
          <div class="text-sm text-slate-500">Tanh</div>
          <div class="text-xl font-semibold">\( \tanh(x) \)</div>
          <div class="text-xs text-slate-500">Range: (−1, 1)</div>
          <canvas class="mt-3 h-28" data-act="tanh"></canvas>
        </div>
        <div class="bg-white rounded-2xl shadow p-4 border border-slate-200">
          <div class="text-sm text-slate-500">Swish</div>
          <div class="text-xl font-semibold">\( \text{swish}(x)=x\,\sigma(x) \)</div>
          <div class="text-xs text-slate-500">Range: (−∞, ∞)</div>
          <canvas class="mt-3 h-28" data-act="swish"></canvas>
        </div>
        <div class="bg-white rounded-2xl shadow p-4 border border-slate-200">
          <div class="text-sm text-slate-500">GELU</div>
          <div class="text-xl font-semibold">\( \text{GELU}(x)=x\,\Phi(x) \)</div>
          <div class="text-xs text-slate-500">Range: (−∞, ∞)</div>
          <canvas class="mt-3 h-28" data-act="gelu"></canvas>
        </div>
        <div class="bg-white rounded-2xl shadow p-4 border border-slate-200 md:col-span-2 lg:col-span-3">
          <div class="text-sm text-slate-500">Softmax (output)</div>
          <div class="text-xl font-semibold">\( \text{softmax}(z_i)=\frac{e^{z_i}}{\sum_j e^{z_j}} \)</div>
          <div class="text-xs text-slate-500">Converts logits to probabilities across classes.</div>
        </div>
      </div>
    </div>
  </section>

  <!-- Losses & Metrics -->
  <section id="losses" class="py-12">
    <div class="max-w-7xl mx-auto px-6">
      <h2 class="text-3xl font-bold tracking-tight text-slate-900">Loss Functions & Evaluation Metrics</h2>
      <div class="mt-6 grid lg:grid-cols-2 gap-6">
        <article class="bg-white border border-slate-200 rounded-2xl p-6 shadow">
          <h3 class="text-xl font-semibold">Regression</h3>
          <ul class="mt-2 text-sm leading-7 text-slate-700 list-disc ml-5">
            <li><span class="font-semibold">MSE</span>: \( \frac{1}{n} \sum_i (y_i - \hat{y}_i)^2 \) — smooth gradients,
              penalizes large errors.</li>
            <li><span class="font-semibold">MAE</span>: \( \frac{1}{n} \sum_i |y_i - \hat{y}_i| \) — robust to outliers.
            </li>
            <li><span class="font-semibold">RMSE</span>: \( \sqrt{\text{MSE}} \) — same units as target.</li>
            <li><span class="font-semibold">R²</span> — scale-independent fit quality.</li>
          </ul>
        </article>
        <article class="bg-white border border-slate-200 rounded-2xl p-6 shadow">
          <h3 class="text-xl font-semibold">Classification</h3>
          <ul class="mt-2 text-sm leading-7 text-slate-700 list-disc ml-5">
            <li><span class="font-semibold">Cross-Entropy</span>: \( -\sum_i y_i \, \log \hat{y}_i \) (multi-class).
            </li>
            <li><span class="font-semibold">Binary CE</span>: \( -\,y\log \hat{y} - (1-y)\log (1-\hat{y}) \).</li>
          </ul>
          <div class="mt-4">
            <div class="text-sm text-slate-500">Confusion Matrix & Key Metrics</div>
            <div class="text-xs text-slate-600 mt-1">Accuracy, Precision (\( \tfrac{TP}{TP+FP} \)), Recall (\(
              \tfrac{TP}{TP+FN} \)), F1, ROC-AUC.</div>
            <div class="mt-3 grid grid-cols-3 text-center text-xs">
              <div class="p-2 rounded-lg bg-slate-50 border">Prefer high <span class="font-semibold">Recall</span> for
                medical screening</div>
              <div class="p-2 rounded-lg bg-slate-50 border">Prefer high <span class="font-semibold">Precision</span>
                for spam filters</div>
              <div class="p-2 rounded-lg bg-slate-50 border">Balanced sets → Accuracy OK</div>
            </div>
          </div>
        </article>
      </div>
    </div>
  </section>

<!-- Optimizers & Schedules -->
<section id="optimizers" class="py-12 bg-slate-50">
  <div class="max-w-7xl mx-auto px-6">
    <h2 class="text-3xl font-bold tracking-tight text-slate-900">Optimization & Learning Rate Scheduling</h2>

    <div class="mt-6 grid lg:grid-cols-3 gap-6">
      <!-- Batching quick ref -->
      <article class="bg-white border border-slate-200 rounded-2xl p-6 shadow">
        <h3 class="text-xl font-semibold">Batching</h3>
        <ul class="mt-2 text-sm leading-7 text-slate-700 list-disc ml-5">
          <li><span class="font-semibold">SGD</span> (batch=1): fast, noisy updates.</li>
          <li><span class="font-semibold">Mini-Batch</span> (32–128): practical sweet spot.</li>
          <li><span class="font-semibold">Full-Batch</span>: stable but slow.</li>
        </ul>
        <div class="mt-4 text-xs text-slate-500">
          Mini-batches reduce gradient variance while keeping updates frequent.
        </div>
      </article>

      <!-- Popular Optimizers quick ref -->
      <article class="bg-white border border-slate-200 rounded-2xl p-6 shadow">
        <h3 class="text-xl font-semibold">Popular Optimizers</h3>
        <ul class="mt-2 text-sm leading-7 text-slate-700 list-disc ml-5">
          <li><span class="font-semibold">Adam</span> (lr≈0.001): momentum (β₁) + RMS (β₂) — strong default.</li>
          <li><span class="font-semibold">RMSProp</span> (lr≈0.001): good for RNNs, non-stationary loss.</li>
          <li><span class="font-semibold">AdaGrad</span> (lr≈0.01): sparse features, per-param scaling.</li>
          <li><span class="font-semibold">SGD + Momentum</span> (lr≈0.01, m≈0.9): strong baseline.</li>
        </ul>
        <div class="mt-4 text-xs text-slate-500">
          Adam often wins “out of the box”, but SGD+Momentum can generalize better when tuned.
        </div>
      </article>

      <!-- LR schedulers quick ref -->
      <article class="bg-white border border-slate-200 rounded-2xl p-6 shadow">
        <h3 class="text-xl font-semibold">LR Schedulers</h3>
        <ul class="mt-2 text-sm leading-7 text-slate-700 list-disc ml-5">
          <li><span class="font-semibold">Step Decay</span>: \( \mathrm{lr} = \mathrm{lr}_0\,\gamma^{\lfloor \mathrm{epoch}/s \rfloor} \).</li>
          <li><span class="font-semibold">Cosine Annealing</span>: smooth cycles between \( \eta_{\max},\,\eta_{\min} \).</li>
          <li><span class="font-semibold">Reduce-on-Plateau</span>: drop \( \mathrm{lr} \) when val loss stalls.</li>
          <li><span class="font-semibold">Warmup</span>: gradually ramp to target lr in first epochs.</li>
        </ul>
      </article>
    </div>

    <!-- Interactive Demos -->
    <div class="mt-8 grid lg:grid-cols-2 gap-6">
      <!-- SGD vs Momentum demo -->
      <article x-data="momentumDemo()" x-init="init()"
               class="bg-white border border-slate-200 rounded-2xl p-6 shadow">
        <div class="flex items-center justify-between">
          <h3 class="text-xl font-semibold">SGD vs Momentum — effect of \( m \)</h3>
          <span class="text-xs text-slate-500">Toy loss: \( f(w)=(w-3)^2 \), \( w_0=-5 \)</span>
        </div>

        <div class="mt-4 grid grid-cols-2 gap-4">
          <label class="text-sm">
            <span class="block text-slate-600">Learning rate (lr): <span class="font-mono" x-text="lr.toFixed(4)"></span></span>
            <input type="range" min="0.0005" max="0.05" step="0.0005" x-model.number="lr" @input="update()"
                   class="w-full accent-slate-700">
          </label>
          <label class="text-sm">
            <span class="block text-slate-600">Momentum \( m \): <span class="font-mono" x-text="momentum.toFixed(2)"></span></span>
            <input type="range" min="0" max="0.99" step="0.01" x-model.number="momentum" @input="update()"
                   class="w-full accent-slate-700">
          </label>
        </div>

        <div class="mt-4">
          <div class="h-48 relative">
            <canvas id="momChart" class="absolute inset-0"></canvas>
          </div>
          <div class="mt-2 text-xs text-slate-500">
            High \( m \) accelerates along consistent gradients and damps oscillations; too high can overshoot.
          </div>
        </div>
      </article>

      <!-- Adam deep dive -->
      <article x-data="adamDemo()" x-init="init()"
               class="bg-white border border-slate-200 rounded-2xl p-6 shadow">
        <div class="flex items-center justify-between">
          <h3 class="text-xl font-semibold">Adam — momentum (β₁) + adaptive RMS (β₂)</h3>
          <span class="text-xs text-slate-500">Toy loss: \( f(w)=(w-3)^2 \), \( w_0=-5 \)</span>
        </div>

        <p class="mt-3 text-sm text-slate-700 leading-6">
          Updates:
          \( m_t=\beta_1 m_{t-1}+(1-\beta_1)g_t,\;\;
             v_t=\beta_2 v_{t-1}+(1-\beta_2)g_t^2 \).<br>
          Bias-correct:
          \( \hat m_t=\frac{m_t}{1-\beta_1^t},\;
             \hat v_t=\frac{v_t}{1-\beta_2^t} \).<br>
          Step:
          \( w_{t+1}=w_t-\eta\, \frac{\hat m_t}{\sqrt{\hat v_t}+\varepsilon} \).
        </p>

        <div class="mt-4 grid lg:grid-cols-3 gap-4">
          <label class="text-sm">
            <span class="block text-slate-600">Learning rate (η): <span class="font-mono" x-text="lr.toFixed(4)"></span></span>
            <input type="range" min="0.0005" max="0.02" step="0.0005" x-model.number="lr" @input="update()"
                   class="w-full accent-slate-700">
          </label>
          <label class="text-sm">
            <span class="block text-slate-600">β₁ (momentum): <span class="font-mono" x-text="beta1.toFixed(2)"></span></span>
            <input type="range" min="0.7" max="0.99" step="0.01" x-model.number="beta1" @input="update()"
                   class="w-full accent-slate-700">
          </label>
          <label class="text-sm">
            <span class="block text-slate-600">β₂ (RMS memory): <span class="font-mono" x-text="beta2.toFixed(2)"></span></span>
            <input type="range" min="0.8" max="0.999" step="0.001" x-model.number="beta2" @input="update()"
                   class="w-full accent-slate-700">
          </label>
          <label class="text-sm">
            <span class="block text-slate-600">ε: <span class="font-mono" x-text="epsilon.toExponential(1)"></span></span>
            <input type="range" min="1e-10" max="1e-6" step="1e-10" x-model.number="epsilon" @input="update()"
                   class="w-full accent-slate-700">
          </label>
          <label class="text-sm">
            <span class="block text-slate-600">Compare: SGD lr <span class="font-mono" x-text="sgdLr.toFixed(3)"></span></span>
            <input type="range" min="0.001" max="0.05" step="0.001" x-model.number="sgdLr" @input="update()"
                   class="w-full accent-slate-700">
          </label>
          <label class="text-sm">
            <span class="block text-slate-600">Steps: <span class="font-mono" x-text="steps"></span></span>
            <input type="range" min="10" max="200" step="1" x-model.number="steps" @input="update()"
                   class="w-full accent-slate-700">
          </label>
        </div>

        <div class="mt-4">
          <div class="h-48 relative">
            <canvas id="adamChart" class="absolute inset-0"></canvas>
          </div>
          <div class="mt-2 text-xs text-slate-500">
            ↑ β₁ ≈ stronger momentum; ↑ β₂ ≈ smoother RMS estimate. ε prevents tiny-denominator spikes.
          </div>
        </div>
      </article>
    </div>
  </div>
</section>

<script>
  // ===== Shared toy problem: f(w) = (w-3)^2 =====
  function grad(w) { return 2 * (w - 3); }
  function loss(w) { return (w - 3) * (w - 3); }

  // ===== SGD vs Momentum component =====
  function momentumDemo() {
    return {
      lr: 0.01,
      momentum: 0.9,
      steps: 100,
      chart: null,

      init() { this.update(); },
      simulate() {
        const w0 = -5;
        const T = this.steps;
        let wSGD = w0, wMom = w0, v = 0;
        const sgdLoss = [], momLoss = [], labels = [];

        for (let t = 1; t <= T; t++) {
          // SGD
          const g1 = grad(wSGD);
          wSGD = wSGD - this.lr * g1;
          sgdLoss.push(loss(wSGD));

          // Momentum
          const g2 = grad(wMom);
          v = this.momentum * v + g2;   // classical momentum
          wMom = wMom - this.lr * v;
          momLoss.push(loss(wMom));

          labels.push(t);
        }
        return { labels, sgdLoss, momLoss };
      },
      update() {
        const { labels, sgdLoss, momLoss } = this.simulate();

        const ctx = document.getElementById('momChart').getContext('2d');
        if (this.chart) { this.chart.destroy(); } // prevent chart growth
        this.chart = new Chart(ctx, {
          type: 'line',
          data: {
            labels,
            datasets: [
              { label: 'SGD', data: sgdLoss, borderWidth: 2, tension: 0.2 },
              { label: 'Momentum', data: momLoss, borderWidth: 2, tension: 0.2 }
            ]
          },
          options: {
            responsive: true,
            maintainAspectRatio: false,
            animation: false,
            scales: {
              y: { title: { display: true, text: 'Loss' }, type: 'linear' },
              x: { title: { display: true, text: 'Step' } }
            },
            plugins: { legend: { position: 'bottom' } }
          }
        });
      }
    }
  }

  // ===== Adam component =====
  function adamDemo() {
    return {
      lr: 0.005,
      beta1: 0.9,
      beta2: 0.999,
      epsilon: 1e-8,
      sgdLr: 0.02,
      steps: 100,
      chart: null,

      init() { this.update(); },
      simulate() {
        const w0 = -5;
        const T = this.steps;

        // Adam state
        let wA = w0, m = 0, v = 0;
        // SGD baseline
        let wS = w0;

        const adamLoss = [], sgdLoss = [], labels = [];

        for (let t = 1; t <= T; t++) {
          // SGD
          const gS = grad(wS);
          wS = wS - this.sgdLr * gS;
          sgdLoss.push(loss(wS));

          // Adam
          const g = grad(wA);
          m = this.beta1 * m + (1 - this.beta1) * g;
          v = this.beta2 * v + (1 - this.beta2) * (g * g);
          const mHat = m / (1 - Math.pow(this.beta1, t));
          const vHat = v / (1 - Math.pow(this.beta2, t));
          wA = wA - this.lr * (mHat / (Math.sqrt(vHat) + this.epsilon));
          adamLoss.push(loss(wA));

          labels.push(t);
        }
        return { labels, adamLoss, sgdLoss };
      },
      update() {
        const { labels, adamLoss, sgdLoss } = this.simulate();
        const ctx = document.getElementById('adamChart').getContext('2d');
        if (this.chart) { this.chart.destroy(); } // prevent chart growth
        this.chart = new Chart(ctx, {
          type: 'line',
          data: {
            labels,
            datasets: [
              { label: 'Adam', data: adamLoss, borderWidth: 2, tension: 0.2 },
              { label: 'SGD (baseline)', data: sgdLoss, borderWidth: 2, tension: 0.2 }
            ]
          },
          options: {
            responsive: true,
            maintainAspectRatio: false,
            animation: false,
            scales: {
              y: { title: { display: true, text: 'Loss' }, type: 'linear' },
              x: { title: { display: true, text: 'Step' } }
            },
            plugins: { legend: { position: 'bottom' } }
          }
        });
      }
    }
  }
</script>

  <!-- Initialization & Depth Demo -->
  <section id="init-and-depth" class="py-12 bg-slate-50">
    <div class="max-w-7xl mx-auto px-6">
      <h2 class="text-3xl font-bold tracking-tight text-slate-900">Initialization, Depth & Signal Propagation</h2>
      <p class="mt-2 text-slate-600 max-w-3xl">Bad initialization leads to exploding/vanishing activations. This demo
        shows expected layer-wise variance for different schemes.</p>

<div x-data="initDemo()" x-init="mount()" class="mt-6 grid grid-cols-1 lg:grid-cols-2 gap-6">
  <div class="bg-white rounded-2xl shadow p-6 border">
    <div class="flex flex-wrap items-center gap-4 text-sm">
      <label>Depth
        <input type="range" min="2" max="12" step="1" x-model.number="L" @input="recompute()" />
        <span class="mono ml-1" x-text="L"></span>
      </label>
      <label>Fan-in
        <input type="range" min="32" max="512" step="32" x-model.number="fan" @input="recompute()" />
        <span class="mono ml-1" x-text="fan"></span>
      </label>
      <label>Scheme
        <select x-model="scheme" @change="recompute()" class="ml-1 border rounded px-2 py-1">
          <option value="he">He (ReLU)</option>
          <option value="xavier">Xavier (tanh)</option>
          <option value="custom">Custom</option>
        </select>
      </label>
      <template x-if="scheme==='custom'">
        <label>Var scale κ
          <input type="range" min="0.2" max="3.0" step="0.05" x-model.number="kappa" @input="recompute()" />
          <span class="mono ml-1" x-text="kappa.toFixed(2)"></span>
        </label>
      </template>
    </div>

    <!-- canvas stays the same id -->
    <canvas id="varChart" style="width:100%; height:260px;" class="border rounded-lg mt-4"></canvas>

    <p class="hint mt-2">
      For ReLU, He init uses \( \mathrm{Var}(W)=\tfrac{2}{n_{\text{in}}} \).
      For tanh, Xavier uses \( \tfrac{1}{n_{\text{in}}} \).
    </p>
  </div>

  <div class="bg-white rounded-2xl shadow p-6 border">
    <h3 class="text-xl font-semibold">Takeaways</h3>
    <ul class="mt-3 text-sm leading-7 text-slate-700 list-disc ml-5">
      <li><span class="font-semibold">He</span> keeps variance stable under ReLU’s 50% gating.</li>
      <li><span class="font-semibold">Xavier</span> balances pre-activation variance for tanh/sigmoid.</li>
      <li>Too small variance → <em>vanishing</em> signals; too large → <em>exploding</em> signals.</li>
      <li>Normalization (Batch/Layer Norm) further stabilizes deep nets.</li>
    </ul>
    <div class="mt-4 p-3 rounded-xl bg-slate-50 border text-xs">
      Expected variance recursion (heuristic): \[
      \mathrm{Var}[a^{(l)}] \approx \rho\,\mathrm{Var}[z^{(l)}],\quad
      \mathrm{Var}[z^{(l)}] \approx \mathrm{Var}[W^{(l)}]\,n_{\text{in}}\,\mathrm{Var}[a^{(l-1)}]
      \] with \(\rho\approx \tfrac12\) for ReLU.
    </div>
  </div>
</div>

    </div>
  </section>

  <!-- Regularization & Skips -->
  <section id="regularization" class="py-12">
    <div class="max-w-7xl mx-auto px-6">
      <h2 class="text-3xl font-bold tracking-tight text-slate-900">Regularization & Skip Connections</h2>
      <div class="mt-6 grid lg:grid-cols-3 gap-6">
        <article class="bg-white border border-slate-200 rounded-2xl p-6 shadow">
          <h3 class="text-xl font-semibold">Regularizers</h3>
          <ul class="mt-2 text-sm leading-7 text-slate-700 list-disc ml-5">
            <li><span class="font-semibold">L2 (Weight Decay)</span>: $L' = L + \lambda \lVert w \rVert^2$ — smooths
              weights.</li>
            <li><span class="font-semibold">L1</span>: $L' = L + \lambda \lVert w \rVert_1$ — sparsity.</li>
            <li><span class="font-semibold">Dropout</span>: zero activations during training.</li>
            <li><span class="font-semibold">Early Stopping</span>: stop when val loss rises.</li>
            <li><span class="font-semibold">Batch/Layer Norm</span>: stabilize & speed training.</li>
          </ul>
        </article>
        <article class="bg-white border border-slate-200 rounded-2xl p-6 shadow">
          <h3 class="text-xl font-semibold">Skip Connections</h3>
          <p class="mt-2 text-sm leading-7 text-slate-700">Residual links improve gradient flow: $y = F(x) + x$.</p>
          <svg viewBox="0 0 560 120" class="w-full h-auto mt-2">
            <defs>
              <marker id="ar2" markerWidth="6" markerHeight="6" refX="5" refY="3" orient="auto"
                markerUnits="strokeWidth">
                <path d="M0,0 L0,6 L6,3 z" fill="#94a3b8" />
              </marker>
            </defs>
            <g stroke="#94a3b8" stroke-width="2" fill="none" marker-end="url(#ar2)">
              <rect x="40" y="20" width="80" height="30" rx="8" fill="#fff" stroke="#e2e8f0" />
              <rect x="160" y="20" width="80" height="30" rx="8" fill="#fff" stroke="#e2e8f0" />
              <rect x="280" y="20" width="80" height="30" rx="8" fill="#fff" stroke="#e2e8f0" />
              <line x1="120" y1="35" x2="160" y2="35" />
              <line x1="240" y1="35" x2="280" y2="35" />
              <!-- skip -->
              <path d="M60,90 C150,110 290,110 340,90" />
              <line x1="320" y1="75" x2="360" y2="75" />
            </g>
            <text x="420" y="40" fill="#334155" font-size="12">y = F(x) + x</text>
          </svg>
        </article>
<article class="bg-white border border-slate-200 rounded-2xl p-6 shadow">
  <h3 class="text-xl font-semibold">Generalization Curves (Toy)</h3>

  <!-- Use CSS size; JS will scale content to fit this box -->
  <canvas id="genChart" class="border rounded-lg w-full h-56"></canvas>

  <p class="hint mt-2">Illustrative: train vs val loss with/without weight decay.</p>
</article>

      </div>
    </div>
  </section>
<!-- Layers Overview & Recipes -->
<section id="layers" class="py-12 bg-slate-50">
  <div class="max-w-7xl mx-auto px-6">
    <h2 class="text-3xl font-bold tracking-tight text-slate-900">Layer Types & Quick Recipes</h2>

    <!-- ========== Core Building Blocks ========== -->
    <h3 class="mt-8 text-xl font-semibold text-slate-900">Core Blocks</h3>
    <div class="mt-4 grid lg:grid-cols-4 gap-4">
      <div class="bg-white rounded-2xl shadow p-4 border">
        <div class="text-sm text-slate-500">Dense (Fully Connected)</div>
        <div class="text-xs text-slate-600 mt-2">Feature mixing, classification/regression.</div>
        <div class="text-xs mt-1">\( z = W x + b \)</div>
      </div>
      <div class="bg-white rounded-2xl shadow p-4 border">
        <div class="text-sm text-slate-500">Dropout</div>
        <div class="text-xs text-slate-600 mt-2">Randomly zero activations (train only).</div>
        <div class="text-xs mt-1">\( y = x \odot \text{mask} \)</div>
      </div>
      <div class="bg-white rounded-2xl shadow p-4 border">
        <div class="text-sm text-slate-500">Batch Norm</div>
        <div class="text-xs text-slate-600 mt-2">Normalize per batch to stabilize training.</div>
        <div class="text-xs mt-1">\( y=\gamma\,\frac{x-\mu}{\sigma+\varepsilon}+\beta \)</div>
      </div>
      <div class="bg-white rounded-2xl shadow p-4 border">
        <div class="text-sm text-slate-500">Layer Norm</div>
        <div class="text-xs text-slate-600 mt-2">Normalize per example (seq models).</div>
        <div class="text-xs mt-1">\( y=\gamma\,\frac{x-\mu}{\sigma+\varepsilon}+\beta \)</div>
      </div>
      <div class="bg-white rounded-2xl shadow p-4 border">
        <div class="text-sm text-slate-500">RMSNorm</div>
        <div class="text-xs text-slate-600 mt-2">Mean-free normalization; cheaper & stable.</div>
        <div class="text-xs mt-1">
          \( \mathrm{rms}(x)=\sqrt{\tfrac{1}{d}\sum_i x_i^2+\varepsilon},\quad
          y=\gamma \cdot \tfrac{x}{\mathrm{rms}(x)} \)
        </div>
        <div class="text-[11px] text-slate-500 mt-1">Common in pre-norm Transformers.</div>
      </div>
      <div class="bg-white rounded-2xl shadow p-4 border">
        <div class="text-sm text-slate-500">Group Norm</div>
        <div class="text-xs text-slate-600 mt-2">Normalize per sample, per channel groups.</div>
        <div class="text-xs mt-1">\( y=\gamma \tfrac{x-\mu_G}{\sigma_G+\varepsilon} + \beta \)</div>
        <div class="text-[11px] text-slate-500 mt-1">Robust with tiny batches (vision).</div>
      </div>
    </div>

    <!-- ========== Recurrent Networks (LSTM/GRU) ========== -->
    <h3 class="mt-10 text-xl font-semibold text-slate-900">Recurrent Networks (LSTM / GRU)</h3>
    <p class="text-sm text-slate-600 mt-1">Temporal dependencies in sequences; good baselines for time series, NLP, control.</p>
    <div class="mt-4 grid lg:grid-cols-3 gap-4">
      <div class="bg-white rounded-2xl shadow p-4 border">
        <div class="text-sm text-slate-500">LSTM Cell</div>
        <div class="text-xs text-slate-600 mt-2 leading-6">
          \( i=\sigma(W_i x_t+U_i h_{t-1}+b_i) \)<br/>
          \( f=\sigma(W_f x_t+U_f h_{t-1}+b_f) \)<br/>
          \( o=\sigma(W_o x_t+U_o h_{t-1}+b_o) \)<br/>
          \( \tilde{c}=\tanh(W_c x_t+U_c h_{t-1}+b_c) \)<br/>
          \( c_t=f\odot c_{t-1}+i\odot \tilde{c},\quad h_t=o\odot\tanh(c_t) \)
        </div>
      </div>
      <div class="bg-white rounded-2xl shadow p-4 border">
        <div class="text-sm text-slate-500">GRU Cell</div>
        <div class="text-xs text-slate-600 mt-2 leading-6">
          \( z=\sigma(W_z x_t+U_z h_{t-1}) \),\;
          \( r=\sigma(W_r x_t+U_r h_{t-1}) \)<br/>
          \( \tilde{h}=\tanh(W_h x_t+U_h(r\odot h_{t-1})) \)<br/>
          \( h_t=(1-z)\odot h_{t-1}+z\odot \tilde{h} \)
        </div>
      </div>
      <article class="bg-white border border-slate-200 rounded-2xl p-4 shadow">
        <h4 class="text-sm font-semibold">Recipe: Sequence Classification</h4>
        <ul class="mt-2 text-xs leading-6 text-slate-700 list-disc ml-5">
          <li>Embed → BiLSTM(128) → Pool(max/last) → Dense(ℓ2) → Dense(C) softmax</li>
          <li>Loss: CE; Optim: AdamW(1e-3); Dropout 0.3; Grad clip=1.0</li>
        </ul>
      </article>
    </div>

    <!-- ========== Convolutional Networks (CNN) ========== -->
    <h3 class="mt-10 text-xl font-semibold text-slate-900">Convolutional Networks (CNN)</h3>
    <p class="text-sm text-slate-600 mt-1">Local receptive fields; translation equivariance; fast on images/audio.</p>
    <div class="mt-4 grid lg:grid-cols-4 gap-4">
      <div class="bg-white rounded-2xl shadow p-4 border">
        <div class="text-sm text-slate-500">Conv 1D/2D</div>
        <div class="text-xs text-slate-600 mt-2">
          \( y_{i} = \sum_{k} w_k\,x_{i-k} \) (1D),
          \( (K\!*X)(u,v)=\sum_{a,b}K(a,b)X(u-a,v-b) \) (2D)
        </div>
      </div>
      <div class="bg-white rounded-2xl shadow p-4 border">
        <div class="text-sm text-slate-500">Depthwise Separable</div>
        <div class="text-xs text-slate-600 mt-2">Depthwise conv + pointwise (1×1) conv → fewer params, fast.</div>
      </div>
      <div class="bg-white rounded-2xl shadow p-4 border">
        <div class="text-sm text-slate-500">Residual Block</div>
        <div class="text-xs text-slate-600 mt-2">Skip connections for stable deep training.</div>
        <div class="text-xs mt-1">\( y = F(x)+x \)</div>
      </div>
      <article class="bg-white border border-slate-200 rounded-2xl p-4 shadow lg:col-span-1">
        <h4 class="text-sm font-semibold">Recipe: Image Classification</h4>
        <ul class="mt-2 text-xs leading-6 text-slate-700 list-disc ml-5">
          <li>[Conv(32,3)→BN→ReLU]×2 → Pool → [Conv(64,3)]×2 → Pool → GAP → Dense(C) softmax</li>
          <li>Augment: flip/crop; Optim: AdamW(3e-4); Label smoothing 0.1</li>
        </ul>
      </article>
    </div>

    <!-- ========== Graph Neural Networks (GNN) ========== -->
    <h3 class="mt-10 text-xl font-semibold text-slate-900">Graph Neural Networks (GNN)</h3>
    <p class="text-sm text-slate-600 mt-1">Operate on nodes/edges; exploit topology via message passing.</p>
    <div class="mt-4 grid lg:grid-cols-3 gap-4">
      <div class="bg-white rounded-2xl shadow p-4 border">
        <div class="text-sm text-slate-500">GCN Layer</div>
        <div class="text-xs text-slate-600 mt-2">
          \( \hat{A}=A+I,\; \hat{D}_{ii}=\sum_j \hat{A}_{ij} \)<br/>
          \( H^{(l+1)}=\sigma(\hat{D}^{-1/2}\hat{A}\hat{D}^{-1/2} H^{(l)} W^{(l)}) \)
        </div>
      </div>
      <div class="bg-white rounded-2xl shadow p-4 border">
        <div class="text-sm text-slate-500">GAT Layer</div>
        <div class="text-xs text-slate-600 mt-2 leading-6">
          \( e_{ij}=\text{LeakyReLU}(a^\top[W h_i \Vert W h_j]) \),\;
          \( \alpha_{ij}=\text{softmax}_j(e_{ij}) \)<br/>
          \( h_i'=\sigma\!\big(\sum_{j\in \mathcal{N}(i)} \alpha_{ij} W h_j\big) \)
        </div>
      </div>
      <article class="bg-white border border-slate-200 rounded-2xl p-4 shadow">
        <h4 class="text-sm font-semibold">Recipe: Node Classification</h4>
        <ul class="mt-2 text-xs leading-6 text-slate-700 list-disc ml-5">
          <li>Input features → GCN(64) ReLU → Dropout(0.5) → GCN(C) → softmax</li>
          <li>Loss: CE; Add self-loops; Use normalized adjacency</li>
        </ul>
      </article>
    </div>

    <!-- ========== Attention & Transformers ========== -->
    <h3 class="mt-10 text-xl font-semibold text-slate-900">Attention & Transformers</h3>
    <p class="text-sm text-slate-600 mt-1">Model long-range dependencies with content-based weighting.</p>
    <div class="mt-4 grid lg:grid-cols-3 gap-4">
      <div class="bg-white rounded-2xl shadow p-4 border">
        <div class="text-sm text-slate-500">Scaled Dot-Product Attn</div>
        <div class="text-xs text-slate-600 mt-2">
          \( \mathrm{Attn}(Q,K,V)=\mathrm{softmax}\!\left(\frac{QK^\top}{\sqrt{d_k}}\right)V \)
        </div>
      </div>
      <div class="bg-white rounded-2xl shadow p-4 border">
        <div class="text-sm text-slate-500">Multi-Head Attention</div>
        <div class="text-xs text-slate-600 mt-2 leading-6">
          \( \mathrm{MHA}(X)=\mathrm{Concat}\big(\mathrm{Attn}(XW_Q^{(i)},XW_K^{(i)},XW_V^{(i)})\big)_{i=1}^h W_O \)
        </div>
        <div class="text-[11px] text-slate-500 mt-1">Use RMSNorm/LayerNorm + residuals.</div>
      </div>
      <article class="bg-white border border-slate-200 rounded-2xl p-4 shadow">
        <h4 class="text-sm font-semibold">Recipe: Transformer Encoder (Seq)</h4>
        <ul class="mt-2 text-xs leading-6 text-slate-700 list-disc ml-5">
          <li>Embed + PosEnc → [RMSNorm → MHA → Resid] → [RMSNorm → FFN → Resid] × L</li>
          <li>Pool (CLS/mean) → Dense(C) softmax; Optim: AdamW(2e-4); Warmup + cosine decay</li>
        </ul>
      </article>
    </div>

    <!-- ========== Classic Recipes ========== -->
    <h3 class="mt-10 text-xl font-semibold text-slate-900">Classic Recipes</h3>
    <div class="mt-4 grid lg:grid-cols-3 gap-6">
      <article class="bg-white border border-slate-200 rounded-2xl p-6 shadow">
        <h4 class="text-lg font-semibold">Binary Classification</h4>
        <ul class="mt-2 text-sm leading-7 text-slate-700 list-disc ml-5">
          <li>Input → Dense(64) ReLU → Dense(64) ReLU → Dense(1) <span class="mono">sigmoid</span></li>
          <li>Loss: BCE; Optim: AdamW(1e-3); Batch: 64; Track AUC</li>
        </ul>
      </article>
      <article class="bg-white border border-slate-200 rounded-2xl p-6 shadow">
        <h4 class="text-lg font-semibold">Multi-class</h4>
        <ul class="mt-2 text-sm leading-7 text-slate-700 list-disc ml-5">
          <li>Input → Dense(128) ReLU → Dropout(0.2) → Dense(64) ReLU → Dense(C) <span class="mono">softmax</span></li>
          <li>Loss: CE; Metrics: accuracy, macro-F1; Label smoothing optional</li>
        </ul>
      </article>
      <article class="bg-white border border-slate-200 rounded-2xl p-6 shadow">
        <h4 class="text-lg font-semibold">Regression</h4>
        <ul class="mt-2 text-sm leading-7 text-slate-700 list-disc ml-5">
          <li>Input → Dense(128) ReLU → Dense(64) ReLU → Dense(1) (linear)</li>
          <li>Loss: MSE/Huber; Scale targets; Report RMSE / \(R^2\)</li>
        </ul>
      </article>
    </div>
  </div>
</section>

  <!-- Best Practices / Debugging -->
  <section id="tips" class="py-12">
    <div class="max-w-7xl mx-auto px-6">
      <h2 class="text-3xl font-bold tracking-tight text-slate-900">Best Practices & Debugging</h2>
      <div class="mt-6 grid lg:grid-cols-3 gap-6">
        <article class="bg-white border border-slate-200 rounded-2xl p-6 shadow">
          <h3 class="text-xl font-semibold">Architecture & Training</h3>
          <ul class="mt-2 text-sm leading-7 text-slate-700 list-disc ml-5">
            <li>Start simple (1–2 hidden layers); scale up gradually.</li>
            <li>Hidden sizes as powers of two (64/128/256/512).</li>
            <li>ReLU family in hidden layers; task-specific outputs.</li>
            <li>Adam with <span>\( \text{lr}\approx 10^{-3} \)</span>, batch 32–128 as a safe default.</li>
            <li>Use early stopping; track train/val curves.</li>
          </ul>
        </article>
        <article class="bg-white border border-slate-200 rounded-2xl p-6 shadow">
          <h3 class="text-xl font-semibold">Choose Your Metric</h3>
          <div class="mt-2 text-sm leading-7 text-slate-700 space-y-2">
            <div class="p-2 rounded-lg bg-slate-50 border">Medical diagnosis → prioritize <span
                class="font-semibold">Recall</span>.</div>
            <div class="p-2 rounded-lg bg-slate-50 border">Spam detection → prioritize <span
                class="font-semibold">Precision</span>.</div>
            <div class="p-2 rounded-lg bg-slate-50 border">Balanced datasets → <span
                class="font-semibold">Accuracy</span> is fine.</div>
          </div>
        </article>
        <article class="bg-white border border-slate-200 rounded-2xl p-6 shadow">
          <h3 class="text-xl font-semibold">Troubleshooting</h3>
          <ul class="mt-2 text-sm leading-7 text-slate-700 list-disc ml-5">
            <li><span class="font-semibold">Vanishing gradients</span>: use ReLU/skip connections; good init.</li>
            <li><span class="font-semibold">Exploding gradients</span>: gradient clipping; lower lr.</li>
            <li><span class="font-semibold">Overfitting</span>: L2/Dropout; more data; early stop.</li>
            <li>Inspect weight/grad histograms and learning curves.</li>
          </ul>
        </article>
      </div>
    </div>
  </section>

  <!-- Footer -->
  <footer class="py-10 bg-slate-900 text-slate-200">
    <div class="max-w-7xl mx-auto px-6">
      <div class="flex flex-col md:flex-row items-center justify-between gap-4">
        <p class="text-sm">© <span id="year"></span> NN Basics Cheatsheet — Single-file</p>
        <div class="text-xs text-slate-400">Tailwind • Alpine.js • Chart.js • MathJax • SVG</div>
      </div>
    </div>
  </footer>

  <!-- Logic: tiny charts for activations + toy curves -->
  <script>
    // Footer year
    document.addEventListener('DOMContentLoaded', () => {
      const y = document.getElementById('year'); if (y) y.textContent = new Date().getFullYear();
    });

    // Toy training curves (loss and cosine lr)
    (function lossSpark() {
      const ctx = document.getElementById('sparkLoss'); if (!ctx || !Chart) return;
      const N = 120;
      const loss = Array.from({ length: N }, (_, i) => 1.2 * Math.exp(-i / 35) + 0.06 * Math.sin(i / 5) + 0.06 * Math.max(0, Math.random() - 0.6));
      const lr = Array.from({ length: N }, (_, i) => 0.5 * (1 + Math.cos(Math.PI * i / N)));
      new Chart(ctx.getContext('2d'), {
        type: 'line',
        data: {
          labels: loss.map((_, i) => i + 1), datasets: [
            { label: 'loss', data: loss, yAxisID: 'y', tension: 0.25 },
            { label: 'lr (cosine)', data: lr, yAxisID: 'y1', tension: 0.25 }
          ]
        },
        options: { responsive: true, scales: { y: { type: 'linear', position: 'left' }, y1: { type: 'linear', position: 'right', grid: { drawOnChartArea: false } } }, plugins: { legend: { display: true } } }
      });
    })();

    // Activation mini-plots
    (function activationCards() {
      const els = Array.from(document.querySelectorAll('canvas[data-act]'));
      if (!els.length || !Chart) return;
      for (const el of els) {
        const kind = el.getAttribute('data-act');
        const xs = []; const ys = [];
        for (let i = 0; i <= 120; i++) { const x = -4 + 8 * (i / 120); xs.push(+x.toFixed(2)); ys.push(act(kind, x)); }
        new Chart(el.getContext('2d'), { type: 'line', data: { labels: xs, datasets: [{ data: ys }] }, options: { responsive: true, plugins: { legend: { display: false } }, elements: { point: { radius: 0 } }, scales: { x: { display: false }, y: { display: false } } } });
      }
      function act(k, x) {
        if (k === 'relu') return Math.max(0, x);
        if (k === 'lrelu') return x > 0 ? x : 0.1 * x;
        if (k === 'sigmoid') return 1 / (1 + Math.exp(-x));
        if (k === 'tanh') return Math.tanh(x);
        if (k === 'swish') { const s = 1 / (1 + Math.exp(-x)); return x * s; }
        if (k === 'gelu') { const c = 0.5 * (1 + erf(x / Math.SQRT2)); return x * c; }
        return x;
      }
      function erf(x) {
        // Abramowitz-Stegun approximation
        const a1 = 0.254829592, a2 = -0.284496736, a3 = 1.421413741, a4 = -1.453152027, a5 = 1.061405429, p = 0.3275911;
        const sign = x < 0 ? -1 : 1; x = Math.abs(x); const t = 1 / (1 + p * x);
        const y = 1 - ((((a5 * t + a4) * t + a3) * t + a2) * t + a1) * t * Math.exp(-x * x);
        return sign * y;
      }
    })();

    // Ensure MathJax typesets after charts/DOM ready (covers async loading)
    (function ensureMathJax() {
      function typesetNow() {
        if (window.MathJax && MathJax.typesetPromise) MathJax.typesetPromise();
      }
      if (document.readyState === 'complete' || document.readyState === 'interactive') {
        // Wait a tick for MathJax to load if deferred
        setTimeout(typesetNow, 50);
      } else {
        document.addEventListener('DOMContentLoaded', () => setTimeout(typesetNow, 50));
      }
      // Safety: typeset again after a short delay (in case of late loads)
      setTimeout(typesetNow, 400);
    })();
  </script>

  <script>
function initDemo(){
  return {
    L: 6, fan: 128, scheme: 'he', kappa: 1.0,
    ctx: null, data: [],

    mount(){
      const c = document.getElementById('varChart');
      this.ctx = c.getContext('2d', { alpha: false });
      // initial compute + render and keep it sharp on resize
      this.recompute();
      window.addEventListener('resize', () => this.render(), { passive: true });
    },

    varW(){
      if (this.scheme === 'he')     return 2 / this.fan;   // ReLU
      if (this.scheme === 'xavier') return 1 / this.fan;   // tanh/sigmoid
      return this.kappa / this.fan;                        // custom
    },

    recompute(){
      const L = Math.max(1, Math.floor(this.L));
      const rho = 0.5;            // ReLU gating E[ReLU^2]/Var ≈ 0.5
      const vW  = this.varW();
      const out = [];
      let varA  = 1.0;            // Var[a^0] = 1
      for (let l = 1; l <= L; l++){
        const varZ = vW * this.fan * varA; // Var[z^l]
        varA = rho * varZ;                 // Var[a^l]
        out.push({ layer: l, std: Math.sqrt(varA), variance: varA });
      }
      this.data = out;
      this.render();
    },

    render(){
      if (!this.ctx) return;
      const ctx = this.ctx;
      const c   = ctx.canvas;

      // Match canvas to CSS size and devicePixelRatio for crispness
      const ratio = window.devicePixelRatio || 1;
      const cssW  = c.clientWidth  || 480;
      const cssH  = c.clientHeight || 240;
      const wantW = Math.floor(cssW * ratio);
      const wantH = Math.floor(cssH * ratio);
      if (c.width !== wantW || c.height !== wantH){
        c.width = wantW; c.height = wantH;
        ctx.setTransform(ratio, 0, 0, ratio, 0, 0); // use CSS pixel space
      }

      // Clear background
      ctx.clearRect(0, 0, cssW, cssH);
      ctx.fillStyle = '#ffffff';
      ctx.fillRect(0, 0, cssW, cssH);

      // Plot area
      const pad = { l: 44, r: 12, t: 16, b: 34 };
      const w = Math.max(10, cssW - pad.l - pad.r);
      const h = Math.max(10, cssH - pad.t - pad.b);

      // Axes
      ctx.strokeStyle = '#94a3b8';
      ctx.lineWidth = 1;
      ctx.beginPath();
      ctx.moveTo(pad.l, pad.t);
      ctx.lineTo(pad.l, pad.t + h);
      ctx.lineTo(pad.l + w, pad.t + h);
      ctx.stroke();

      if (this.data.length === 0) return;

      // Y scale on std
      const maxStd  = Math.max(...this.data.map(d => d.std), 1e-9);
      const niceMax = this._niceUpper(maxStd);
      const y = (v) => pad.t + h - (v / niceMax) * h;

      // Grid + ticks
      ctx.fillStyle = '#64748b';
      ctx.font = '12px system-ui, -apple-system, Segoe UI, Roboto, Arial';
      ctx.textAlign = 'right';
      ctx.textBaseline = 'middle';
      const ticks = 4;
      for (let i = 0; i <= ticks; i++){
        const tv = (niceMax * i) / ticks;
        const yy = y(tv);
        ctx.strokeStyle = i === 0 ? '#94a3b8' : '#e2e8f0';
        ctx.beginPath();
        ctx.moveTo(pad.l, yy);
        ctx.lineTo(pad.l + w, yy);
        ctx.stroke();
        ctx.fillText(tv.toFixed(2), pad.l - 6, yy);
      }

      // Bars
      const n = this.data.length;
      const gap  = Math.min(14, (w / n) * 0.2);
      const barW = Math.max(2, (w / n) - gap);
      ctx.textAlign = 'center';
      ctx.textBaseline = 'top';

      this.data.forEach((d, i) => {
        const x0 = pad.l + i * (barW + gap) + gap * 0.5;
        const y0 = y(d.std);
        const bh = (pad.t + h) - y0;

        // bar
        ctx.fillStyle = '#3b82f6';
        ctx.fillRect(x0, y0, barW, bh);

        // label
        ctx.fillStyle = '#475569';
        ctx.fillText(`L${d.layer}`, x0 + barW / 2, pad.t + h + 6);
      });

      // Title
      ctx.fillStyle = '#0f172a';
      ctx.textAlign = 'left';
      ctx.textBaseline = 'alphabetic';
      ctx.font = '600 14px system-ui, -apple-system, Segoe UI, Roboto, Arial';
      const schemeLabel = this.scheme === 'custom' ? `custom (κ=${this.kappa})` : this.scheme;
      ctx.fillText(`Activation std per layer — scheme: ${schemeLabel}, fan=${this.fan}`, pad.l, 14);
    },

    _niceUpper(v){
      if (v <= 0) return 1;
      const exp  = Math.floor(Math.log10(v));
      const base = Math.pow(10, exp);
      const m    = v / base;
      const step = (m <= 1) ? 1 : (m <= 2) ? 2 : (m <= 5) ? 5 : 10;
      return step * base;
    }
  };
}
</script>
<script>
(function(){
  const CANVAS_ID = 'genChart';

  function genToyData(E=50){
    const ep = Array.from({length:E}, (_,i)=>i+1);
    const nrm = ep.map(t => 1.1*Math.exp(-t/14) + 0.02*Math.sin(t/3));            // train (no WD)
    const nrv = ep.map(t => 0.9*Math.exp(-t/22) + 0.25*Math.max(0,(t-18))/E);     // val   (no WD) -> overfit
    const wdt = ep.map(t => 1.25*Math.exp(-t/16) + 0.02*Math.cos(t/4));           // train (WD)
    const wdv = ep.map(t => 0.85*Math.exp(-t/18) + 0.11*Math.max(0,(t-26))/E);    // val   (WD)
    return {ep, nrm, nrv, wdt, wdv};
  }

  function setupCtx(c){
    const dpr = window.devicePixelRatio || 1;
    const cssW = c.clientWidth  || +c.getAttribute('width')  || 480;
    const cssH = c.clientHeight || +c.getAttribute('height') || 220;
    const wantW = Math.floor(cssW * dpr), wantH = Math.floor(cssH * dpr);
    if (c.width !== wantW || c.height !== wantH) {
      c.width = wantW; c.height = wantH;
    }
    const ctx = c.getContext('2d');
    ctx.setTransform(dpr, 0, 0, dpr, 0, 0);  // back to CSS pixels
    return {ctx, cssW, cssH};
  }

  function niceUpper(v){
    if (v<=0) return 1;
    const e=Math.floor(Math.log10(v)), b=10**e, m=v/b;
    return (m<=1?1:m<=2?2:m<=5?5:10)*b;
  }

  function render(){
    const c = document.getElementById(CANVAS_ID);
    if (!c) return;
    const {ctx, cssW, cssH} = setupCtx(c);

    // data
    const {ep, nrm, nrv, wdt, wdv} = genToyData(50);
    const series = [
      {name:'Train (no WD)', data:nrm, stroke:'#ef4444'},
      {name:'Val (no WD)',   data:nrv, stroke:'#f59e0b'},
      {name:'Train (WD)',    data:wdt, stroke:'#3b82f6'},
      {name:'Val (WD)',      data:wdv, stroke:'#10b981'},
    ];

    // clear bg
    ctx.clearRect(0,0,cssW,cssH);
    ctx.fillStyle = '#ffffff';
    ctx.fillRect(0,0,cssW,cssH);

    // layout
    const pad = {l:46,r:14,t:16,b:30};
    const w = cssW - pad.l - pad.r;
    const h = cssH - pad.t - pad.b;

    // scales
    const xmax = ep[ep.length-1];
    const allY = series.flatMap(s=>s.data);
    const ymax = niceUpper(Math.max(...allY));
    const x = t => pad.l + (t-1)/(xmax-1) * w;
    const y = v => pad.t + h - (v / ymax) * h;

    // grid + axes
    ctx.strokeStyle = '#e2e8f0';
    ctx.lineWidth = 1;
    ctx.font = '12px system-ui, -apple-system, Segoe UI, Roboto, Arial';
    ctx.fillStyle = '#64748b';
    ctx.textAlign = 'right';
    ctx.textBaseline = 'middle';

    const yTicks = 4;
    for (let i=0; i<=yTicks; i++){
      const val = (ymax*i)/yTicks, yy = y(val);
      ctx.beginPath(); ctx.moveTo(pad.l, yy); ctx.lineTo(pad.l+w, yy); ctx.stroke();
      ctx.fillText(val.toFixed(2), pad.l-6, yy);
    }
    // x ticks at epochs
    ctx.textAlign = 'center'; ctx.textBaseline = 'top';
    const xTicks = 5;
    for (let i=0; i<=xTicks; i++){
      const t = 1 + i*(xmax-1)/xTicks, xt = x(t), e = Math.round(t);
      ctx.strokeStyle = '#f1f5f9';
      ctx.beginPath(); ctx.moveTo(xt, pad.t); ctx.lineTo(xt, pad.t+h); ctx.stroke();
      ctx.fillStyle = '#64748b';
      ctx.fillText(e, xt, pad.t+h+6);
    }
    // axes frame
    ctx.strokeStyle = '#94a3b8';
    ctx.beginPath();
    ctx.moveTo(pad.l, pad.t); ctx.lineTo(pad.l, pad.t+h); ctx.lineTo(pad.l+w, pad.t+h);
    ctx.stroke();

    // lines
    function drawLine(arr, stroke){
      ctx.beginPath();
      ctx.moveTo(x(1), y(arr[0]));
      for (let i=1;i<arr.length;i++) ctx.lineTo(x(i+1), y(arr[i]));
      ctx.strokeStyle = stroke;
      ctx.lineWidth = 2;
      ctx.stroke();
    }
    series.forEach(s => drawLine(s.data, s.stroke));

    // legend
    const items = series.map(s => s.name);
    const lh = 18, lw = 20, gap = 10;
    let lx = pad.l + 6, ly = pad.t + 6;
    items.forEach((name, i) => {
      const color = series[i].stroke;
      ctx.fillStyle = color;
      ctx.fillRect(lx, ly+4, lw, 6);
      ctx.fillStyle = '#0f172a';
      ctx.textAlign = 'left'; ctx.textBaseline = 'top';
      ctx.fillText(name, lx + lw + 6, ly);
      ly += lh;
      // wrap if needed
      if (ly > pad.t + 6 + 3*lh) { ly = pad.t + 6; lx += 180 + gap; }
    });

  }

  // render now and on resize
  function boot(){
    const c = document.getElementById(CANVAS_ID);
    if (!c) return;
    render();
    window.addEventListener('resize', render, {passive:true});
  }

  // If Alpine is present, wait until next tick; otherwise DOMContentLoaded
  if (window.Alpine) { queueMicrotask(boot); }
  else { window.addEventListener('DOMContentLoaded', boot, {once:true}); }
})();
</script>


</body>

</html>