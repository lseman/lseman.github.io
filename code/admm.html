<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>ADMM Explained — Step-by-Step Pedagogical Guide</title>
    <!-- Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>
    <!-- MathJax (v3) -->
    <script>
        window.MathJax = {
            tex: { inlineMath: [["$", "$"], ["\\(", "\\)"]], displayMath: [["$$", "$$"], ["\\[", "\\]"]] },
            chtml: { linebreaks: { automatic: false }, matchFontHeight: true },
            options: { skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre'] },
            svg: { fontCache: 'global' }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
    <style>
        html {
            scroll-behavior: smooth
        }

        .card {
            backdrop-filter: blur(4px)
        }

        .lbl {
            font-size: 12px;
            fill: #334155;
            font-weight: 600
        }

        .wire {
            stroke: #64748b;
            stroke-width: 2.5;
            fill: none
        }

        .node {
            fill: #f8fafc;
            stroke: #3b82f6;
            stroke-width: 2
        }

        .center {
            fill: #f0fdf4;
            stroke: #16a34a;
            stroke-width: 2
        }

        .edge {
            stroke: #94a3b8;
            stroke-width: 2;
        }

        .math-nowrap {
            overflow-x: auto;
            white-space: nowrap
        }

        .theorem {
            background: #eff6ff;
            border-left: 4px solid #3b82f6;
            padding: .75rem 1rem;
            border-radius: .5rem
        }

        .def {
            background: #f0fdf4;
            border-left: 4px solid #22c55e;
            padding: .75rem 1rem;
            border-radius: .5rem
        }

        .warn {
            background: #fef2f2;
            border-left: 4px solid #ef4444;
            padding: .75rem 1rem;
            border-radius: .5rem
        }

        .insight {
            background: #fefce8;
            border-left: 4px solid #eab308;
            padding: .75rem 1rem;
            border-radius: .5rem
        }

        .step {
            background: #f8fafc;
            border: 2px solid #e2e8f0;
            padding: 1rem;
            border-radius: .75rem;
            margin: 1rem 0
        }

        code {
            background: #f1f5f9;
            padding: .15rem .35rem;
            border-radius: .35rem
        }

        .step-number {
            background: #3b82f6;
            color: white;
            border-radius: 50%;
            width: 28px;
            height: 28px;
            display: inline-flex;
            align-items: center;
            justify-content: center;
            font-weight: bold;
            font-size: 14px
        }
    </style>
</head>

<body class="min-h-screen text-slate-800 bg-gradient-to-br from-slate-50 to-blue-50">

    <!-- ======= Header ======= -->
    <header class="bg-gradient-to-tr from-indigo-50 via-emerald-50 to-cyan-50 border-b border-slate-200">
        <div class="max-w-7xl mx-auto px-6 py-12 lg:py-16">
            <div class="flex flex-col lg:flex-row items-start gap-8">
                <div class="flex-1">
                    <h1 class="text-4xl md:text-5xl font-extrabold tracking-tight text-slate-900">ADMM Explained — <span
                            class="text-indigo-600">Step by Step</span></h1>
                    <p class="mt-3 text-lg md:text-xl text-slate-700 max-w-3xl">A pedagogical guide to understanding the
                        <b>Alternating Direction Method of Multipliers</b> from first principles to federated consensus.
                        Learn why it works, how to implement it, and when to use it.</p>
                    <div class="mt-5 flex flex-wrap gap-3">
                        <a href="#motivation"
                            class="px-4 py-2 rounded-xl bg-indigo-600 text-white font-semibold shadow hover:bg-indigo-700">Why
                            ADMM?</a>
                        <a href="#augmented"
                            class="px-4 py-2 rounded-xl bg-white ring-1 ring-slate-200 shadow-sm font-semibold hover:bg-slate-50">Augmented
                            Lagrangian</a>
                        <a href="#algorithm"
                            class="px-4 py-2 rounded-xl bg-white ring-1 ring-slate-200 shadow-sm font-semibold hover:bg-slate-50">The
                            Algorithm</a>
                        <a href="#consensus"
                            class="px-4 py-2 rounded-xl bg-white ring-1 ring-slate-200 shadow-sm font-semibold hover:bg-slate-50">Consensus
                            Problems</a>
                        <a href="#subproblems"
                            class="px-4 py-2 rounded-xl bg-white ring-1 ring-slate-200 shadow-sm font-semibold hover:bg-slate-50">Solving
                            Subproblems</a>
                        <a href="#practical"
                            class="px-4 py-2 rounded-xl bg-white ring-1 ring-slate-200 shadow-sm font-semibold hover:bg-slate-50">Practical
                            Tips</a>
                    </div>
                </div>
            </div>
        </div>
    </header>

    <!-- ======= Section: Motivation ======= -->
    <section id="motivation" class="py-12">
        <div class="max-w-7xl mx-auto px-6">
            <h2 class="text-3xl font-bold text-center mb-8">Why Do We Need ADMM?</h2>
            <div class="grid lg:grid-cols-2 gap-8">
                <article class="bg-white border border-slate-200 rounded-2xl p-6 shadow card">
                    <h3 class="text-xl font-semibold mb-4">The Challenge: Coupled Optimization</h3>
                    <p class="text-slate-700 mb-4">Consider a machine learning problem where we want to minimize:</p>
                    <div class="math-nowrap mt-2">
                        $$\min_{x,z} f(x) + g(z) \quad \text{subject to} \quad Ax + Bz = c$$
                    </div>
                    <p class="text-slate-700 mt-4">This appears in many scenarios:</p>
                    <ul class="list-disc ml-6 mt-3 text-sm text-slate-700 space-y-2">
                        <li><strong>Regularized problems:</strong> $f(x) = \text{loss}(x)$, $g(z) =
                            \text{regularizer}(z)$, $x = z$</li>
                        <li><strong>Federated learning:</strong> Each device has local data and we want global consensus
                        </li>
                        <li><strong>Distributed computing:</strong> Split large problems across multiple machines</li>
                        <li><strong>Constrained optimization:</strong> Handle complex constraint sets separately</li>
                    </ul>
                </article>

                <article class="bg-white border border-slate-200 rounded-2xl p-6 shadow card">
                    <h3 class="text-xl font-semibold mb-4">Why Not Just Use Gradient Descent?</h3>
                    <div class="warn text-sm">
                        <strong>Problem:</strong> The coupling constraint $Ax + Bz = c$ makes the problem non-separable.
                        We can't optimize $x$ and $z$ independently!
                    </div>
                    <p class="text-slate-700 mt-4">Traditional approaches struggle because:</p>
                    <ul class="list-disc ml-6 mt-3 text-sm text-slate-700 space-y-2">
                        <li><strong>Gradient methods:</strong> Require computing gradients of the full objective, which
                            may not be available or efficient</li>
                        <li><strong>Penalty methods:</strong> Often have numerical issues and require careful tuning
                        </li>
                        <li><strong>Primal-dual methods:</strong> Can be unstable and sensitive to step sizes</li>
                    </ul>
                    <div class="insight text-sm mt-4">
                        <strong>ADMM's insight:</strong> Use the augmented Lagrangian to decouple the variables while
                        maintaining convergence guarantees!
                    </div>
                </article>
            </div>
        </div>
    </section>

    <!-- ======= Section: Augmented Lagrangian ======= -->
    <section id="augmented" class="py-12 bg-slate-50">
        <div class="max-w-7xl mx-auto px-6">
            <h2 class="text-3xl font-bold text-center mb-8">Building the Augmented Lagrangian</h2>

            <div class="step">
                <div class="flex items-center gap-3 mb-4">
                    <span class="step-number">1</span>
                    <h3 class="text-xl font-semibold">Start with the Regular Lagrangian</h3>
                </div>
                <p class="text-slate-700 mb-3">For our constrained problem, the standard Lagrangian is:</p>
                <div class="math-nowrap">
                    $$L(x,z,y) = f(x) + g(z) + y^T(Ax + Bz - c)$$
                </div>
                <p class="text-slate-700 mt-3">where $y$ is the <strong>dual variable</strong> (Lagrange multiplier) for
                    the constraint.</p>
            </div>

            <div class="step">
                <div class="flex items-center gap-3 mb-4">
                    <span class="step-number">2</span>
                    <h3 class="text-xl font-semibold">Add a Quadratic Penalty Term</h3>
                </div>
                <p class="text-slate-700 mb-3">The <strong>augmented Lagrangian</strong> adds a quadratic penalty:</p>
                <div class="math-nowrap">
                    $$\mathcal{L}_\rho(x,z,y) = f(x) + g(z) + y^T(Ax + Bz - c) + \frac{\rho}{2}\|Ax + Bz - c\|_2^2$$
                </div>
                <div class="insight text-sm mt-4">
                    <strong>Why add the penalty?</strong> The quadratic term makes the objective <em>strongly
                        convex</em> in the constraint violation, which improves numerical stability and convergence.
                </div>
            </div>

            <div class="step">
                <div class="flex items-center gap-3 mb-4">
                    <span class="step-number">3</span>
                    <h3 class="text-xl font-semibold">Scaled Form (The Key Simplification)</h3>
                </div>
                <p class="text-slate-700 mb-3">Define the <strong>scaled dual variable</strong> $u = \frac{1}{\rho}y$
                    and complete the square:</p>
                <div class="math-nowrap">
                    $$\mathcal{L}_\rho(x,z,u) = f(x) + g(z) + \frac{\rho}{2}\|Ax + Bz - c + u\|_2^2 -
                    \frac{\rho}{2}\|u\|_2^2$$
                </div>
                <p class="text-slate-700 mt-3">Since the last term doesn't depend on $(x,z)$, we can drop it for
                    optimization:</p>
                <div class="math-nowrap">
                    $$\tilde{\mathcal{L}}_\rho(x,z,u) = f(x) + g(z) + \frac{\rho}{2}\|Ax + Bz - c + u\|_2^2$$
                </div>
                <div class="theorem text-sm mt-4">
                    <strong>Key insight:</strong> The scaled form transforms the constraint violation term into a simple
                    quadratic that's easier to work with computationally.
                </div>
            </div>
        </div>
    </section>

    <!-- ======= Section: The Algorithm ======= -->
    <section id="algorithm" class="py-12">
        <div class="max-w-7xl mx-auto px-6">
            <h2 class="text-3xl font-bold text-center mb-8">The ADMM Algorithm</h2>

            <div class="step">
                <div class="flex items-center gap-3 mb-4">
                    <span class="step-number">1</span>
                    <h3 class="text-xl font-semibold">Alternating Minimization Strategy</h3>
                </div>
                <p class="text-slate-700 mb-3">ADMM alternates between minimizing over $x$ and $z$, then updates the
                    dual variable $u$:</p>

                <div class="grid md:grid-cols-3 gap-4 mt-6">
                    <div class="bg-blue-50 p-4 rounded-lg">
                        <h4 class="font-semibold text-blue-800 mb-2">x-update</h4>
                        <div class="math-nowrap text-sm">
                            $$x^{k+1} = \arg\min_x \mathcal{L}_\rho(x, z^k, u^k)$$
                        </div>
                        <p class="text-xs text-blue-700 mt-2">Minimize over $x$ holding $z$ and $u$ fixed</p>
                    </div>

                    <div class="bg-green-50 p-4 rounded-lg">
                        <h4 class="font-semibold text-green-800 mb-2">z-update</h4>
                        <div class="math-nowrap text-sm">
                            $$z^{k+1} = \arg\min_z \mathcal{L}_\rho(x^{k+1}, z, u^k)$$
                        </div>
                        <p class="text-xs text-green-700 mt-2">Minimize over $z$ using updated $x$</p>
                    </div>

                    <div class="bg-purple-50 p-4 rounded-lg">
                        <h4 class="font-semibold text-purple-800 mb-2">u-update</h4>
                        <div class="math-nowrap text-sm">
                            $$u^{k+1} = u^k + (Ax^{k+1} + Bz^{k+1} - c)$$
                        </div>
                        <p class="text-xs text-purple-700 mt-2">Dual ascent step</p>
                    </div>
                </div>
            </div>

            <div class="step">
                <div class="flex items-center gap-3 mb-4">
                    <span class="step-number">2</span>
                    <h3 class="text-xl font-semibold">Explicit Update Formulas</h3>
                </div>
                <div class="bg-gray-50 p-4 rounded-lg">
                    <div class="math-nowrap">
                        $$\begin{aligned}
                        x^{k+1} &= \arg\min_x \left[ f(x) + \frac{\rho}{2}\|Ax + Bz^k - c + u^k\|_2^2 \right] \\
                        z^{k+1} &= \arg\min_z \left[ g(z) + \frac{\rho}{2}\|Ax^{k+1} + Bz - c + u^k\|_2^2 \right] \\
                        u^{k+1} &= u^k + (Ax^{k+1} + Bz^{k+1} - c)
                        \end{aligned}$$
                    </div>
                </div>
                <div class="insight text-sm mt-4">
                    <strong>Why this works:</strong> Each subproblem is often easier to solve than the original coupled
                    problem. The penalty parameter $\rho$ provides the "spring" that pulls the variables toward
                    satisfying the constraint.
                </div>
            </div>

            <div class="step">
                <div class="flex items-center gap-3 mb-4">
                    <span class="step-number">3</span>
                    <h3 class="text-xl font-semibold">Convergence Monitoring</h3>
                </div>
                <p class="text-slate-700 mb-3">Track two residuals to monitor convergence:</p>
                <div class="grid md:grid-cols-2 gap-4">
                    <div class="bg-red-50 p-4 rounded-lg">
                        <h4 class="font-semibold text-red-800 mb-2">Primal Residual</h4>
                        <div class="math-nowrap text-sm">
                            $$r^k = Ax^k + Bz^k - c$$
                        </div>
                        <p class="text-xs text-red-700 mt-2">Measures constraint violation</p>
                    </div>

                    <div class="bg-orange-50 p-4 rounded-lg">
                        <h4 class="font-semibold text-orange-800 mb-2">Dual Residual</h4>
                        <div class="math-nowrap text-sm">
                            $$s^k = \rho A^T B (z^k - z^{k-1})$$
                        </div>
                        <p class="text-xs text-orange-700 mt-2">Measures dual feasibility</p>
                    </div>
                </div>
                <p class="text-slate-700 mt-4">Stop when both $\|r^k\|_2 \leq \varepsilon_{\text{pri}}$ and $\|s^k\|_2
                    \leq \varepsilon_{\text{dual}}$.</p>
            </div>
        </div>
    </section>

    <!-- ======= Section: Consensus Problems ======= -->
    <section id="consensus" class="py-12 bg-slate-50">
        <div class="max-w-7xl mx-auto px-6">
            <h2 class="text-3xl font-bold text-center mb-8">Understanding Consensus Problems</h2>

            <div class="step">
                <div class="flex items-center gap-3 mb-4">
                    <span class="step-number">1</span>
                    <h3 class="text-xl font-semibold">What is a Consensus Problem?</h3>
                </div>
                <p class="text-slate-700 mb-4">A <strong>consensus problem</strong> occurs when we have multiple
                    "agents" (devices, processors, data centers) that need to agree on a common solution:</p>
                <div class="math-nowrap">
                    $$\min_{\{x_i\}, z} \sum_{i=1}^K f_i(x_i) + g(z) \quad \text{subject to} \quad x_i = z \text{ for
                    all } i$$
                </div>
                <div class="grid md:grid-cols-2 gap-6 mt-6">
                    <div>
                        <h4 class="font-semibold mb-2">Real-world examples:</h4>
                        <ul class="list-disc ml-6 text-sm text-slate-700 space-y-1">
                            <li><strong>Federated learning:</strong> Each phone has local data, wants shared model</li>
                            <li><strong>Distributed optimization:</strong> Split computation across data centers</li>
                            <li><strong>Multi-task learning:</strong> Related tasks should have similar parameters</li>
                            <li><strong>Sensor networks:</strong> Sensors collaborate to estimate a signal</li>
                        </ul>
                    </div>
                    <div>
                        <svg viewBox="0 0 400 200" class="w-full h-auto bg-white rounded-lg p-4">
                            <!-- Center node -->
                            <circle cx="200" cy="100" r="25" class="center" />
                            <text x="200" y="107" class="lbl" text-anchor="middle">z (consensus)</text>

                            <!-- Agent nodes -->
                            <circle cx="80" cy="60" r="20" class="node" />
                            <circle cx="80" cy="140" r="20" class="node" />
                            <circle cx="320" cy="60" r="20" class="node" />
                            <circle cx="320" cy="140" r="20" class="node" />

                            <text x="80" y="67" class="lbl" text-anchor="middle">x₁</text>
                            <text x="80" y="147" class="lbl" text-anchor="middle">x₂</text>
                            <text x="320" y="67" class="lbl" text-anchor="middle">x₃</text>
                            <text x="320" y="147" class="lbl" text-anchor="middle">x₄</text>

                            <!-- Arrows -->
                            <line x1="100" y1="70" x2="175" y2="90" class="wire" marker-end="url(#arrow)" />
                            <line x1="100" y1="130" x2="175" y2="110" class="wire" marker-end="url(#arrow)" />
                            <line x1="300" y1="70" x2="225" y2="90" class="wire" marker-end="url(#arrow)" />
                            <line x1="300" y1="130" x2="225" y2="110" class="wire" marker-end="url(#arrow)" />

                            <defs>
                                <marker id="arrow" markerWidth="10" markerHeight="10" refX="9" refY="3" orient="auto"
                                    markerUnits="strokeWidth">
                                    <path d="M0,0 L0,6 L9,3 z" fill="#64748b" />
                                </marker>
                            </defs>
                        </svg>
                    </div>
                </div>
            </div>

            <div class="step">
                <div class="flex items-center gap-3 mb-4">
                    <span class="step-number">2</span>
                    <h3 class="text-xl font-semibold">Why Use a Consensus Variable z?</h3>
                </div>
                <div class="grid md:grid-cols-2 gap-6">
                    <div>
                        <h4 class="font-semibold mb-3 text-red-800">Without consensus variable:</h4>
                        <div class="bg-red-50 p-4 rounded-lg">
                            <div class="math-nowrap text-sm">
                                $$\min_{\{x_i\}} \sum_{i=1}^K f_i(x_i) + g\left(\frac{1}{K}\sum_i x_i\right)$$
                                $$\text{subject to } x_i = x_j \text{ for all } i,j$$
                            </div>
                            <p class="text-xs text-red-700 mt-2">Coupling makes this hard to decompose</p>
                        </div>
                    </div>
                    <div>
                        <h4 class="font-semibold mb-3 text-green-800">With consensus variable:</h4>
                        <div class="bg-green-50 p-4 rounded-lg">
                            <div class="math-nowrap text-sm">
                                $$\min_{\{x_i\}, z} \sum_{i=1}^K f_i(x_i) + g(z)$$
                                $$\text{subject to } x_i = z \text{ for all } i$$
                            </div>
                            <p class="text-xs text-green-700 mt-2">Clean separation: each agent optimizes locally</p>
                        </div>
                    </div>
                </div>
                <div class="insight text-sm mt-4">
                    <strong>Key insight:</strong> The consensus variable $z$ acts as a "mediator" that allows each agent
                    to optimize independently while maintaining global coordination.
                </div>
            </div>

            <div class="step">
                <div class="flex items-center gap-3 mb-4">
                    <span class="step-number">3</span>
                    <h3 class="text-xl font-semibold">ADMM for Consensus: The Updates</h3>
                </div>
                <div class="bg-gray-50 p-6 rounded-lg">
                    <div class="math-nowrap mb-4">
                        $$\begin{aligned}
                        x_i^{k+1} &= \arg\min_{x} \left[ f_i(x) + \frac{\rho}{2}\|x - z^k + u_i^k\|_2^2 \right] \\
                        z^{k+1} &= \text{prox}_{g/(K\rho)} \left( \frac{1}{K}\sum_{i=1}^K (x_i^{k+1} + u_i^k) \right) \\
                        u_i^{k+1} &= u_i^k + (x_i^{k+1} - z^{k+1})
                        \end{aligned}$$
                    </div>
                    <div class="grid md:grid-cols-3 gap-4 text-sm">
                        <div class="bg-blue-50 p-3 rounded">
                            <strong>Local step:</strong> Each agent $i$ solves its own proximal problem with penalty
                            toward current consensus $z^k - u_i^k$
                        </div>
                        <div class="bg-green-50 p-3 rounded">
                            <strong>Global step:</strong> Update consensus by averaging local solutions and applying
                            proximal operator for $g$
                        </div>
                        <div class="bg-purple-50 p-3 rounded">
                            <strong>Dual step:</strong> Update each agent's dual variable based on how far it is from
                            consensus
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- ======= Section: Solving Subproblems ======= -->
    <section id="subproblems" class="py-12">
        <div class="max-w-7xl mx-auto px-6">
            <h2 class="text-3xl font-bold text-center mb-8">Solving the Subproblems</h2>

            <div class="step">
                <div class="flex items-center gap-3 mb-4">
                    <span class="step-number">1</span>
                    <h3 class="text-xl font-semibold">Understanding Proximal Operators</h3>
                </div>
                <p class="text-slate-700 mb-4">The <strong>proximal operator</strong> of a function $h$ is:</p>
                <div class="math-nowrap">
                    $$\text{prox}_{\gamma h}(v) = \arg\min_x \left[ h(x) + \frac{1}{2\gamma}\|x - v\|_2^2 \right]$$
                </div>
                <div class="insight text-sm mt-4">
                    <strong>Intuition:</strong> Find the point $x$ that best balances minimizing $h(x)$ while staying
                    close to $v$. The parameter $\gamma$ controls the trade-off.
                </div>

                <div class="grid md:grid-cols-2 gap-6 mt-6">
                    <div class="bg-white border border-slate-200 rounded-xl p-4">
                        <h4 class="font-semibold mb-3">Common Proximal Operators</h4>
                        <div class="space-y-3 text-sm">
                            <div>
                                <strong>Soft thresholding (LASSO):</strong>
                                <div class="math-nowrap">$h(x) = \lambda\|x\|_1$</div>
                                <div class="math-nowrap">$\text{prox}_{\gamma h}(v) = \text{sign}(v) \max(|v| -
                                    \gamma\lambda, 0)$</div>
                            </div>
                            <div>
                                <strong>Ridge regression:</strong>
                                <div class="math-nowrap">$h(x) = \frac{\lambda}{2}\|x\|_2^2$</div>
                                <div class="math-nowrap">$\text{prox}_{\gamma h}(v) = \frac{v}{1 + \gamma\lambda}$</div>
                            </div>
                            <div>
                                <strong>Projection onto set $C$:</strong>
                                <div class="math-nowrap">$h(x) = \iota_C(x)$ (indicator function)</div>
                                <div class="math-nowrap">$\text{prox}_{\gamma h}(v) = \Pi_C(v)$ (projection)</div>
                            </div>
                        </div>
                    </div>

                    <div class="bg-white border border-slate-200 rounded-xl p-4">
                        <h4 class="font-semibold mb-3">When Closed Form Isn't Available</h4>
                        <ul class="list-disc ml-6 text-sm text-slate-700 space-y-2">
                            <li><strong>Gradient descent:</strong> For smooth $f_i$, use a few GD steps</li>
                            <li><strong>Newton's method:</strong> For strongly convex problems with available Hessian
                            </li>
                            <li><strong>Coordinate descent:</strong> When the problem has structure</li>
                            <li><strong>Specialized solvers:</strong> For specific problem types (LP, QP, etc.)</li>
                        </ul>
                        <div class="warn text-xs mt-3">
                            <strong>Important:</strong> You don't need to solve subproblems exactly! A few iterations of
                            an iterative method often suffices.
                        </div>
                    </div>
                </div>
            </div>

            <div class="step">
                <div class="flex items-center gap-3 mb-4">
                    <span class="step-number">2</span>
                    <h3 class="text-xl font-semibold">The Local Subproblem (x-update)</h3>
                </div>
                <p class="text-slate-700 mb-3">Each agent solves:</p>
                <div class="math-nowrap">
                    $$x_i^{k+1} = \arg\min_x \left[ f_i(x) + \frac{\rho}{2}\|x - z^k + u_i^k\|_2^2 \right]$$
                </div>

                <div class="bg-blue-50 p-4 rounded-lg mt-4">
                    <h4 class="font-semibold text-blue-800 mb-2">What this means in practice:</h4>
                    <ul class="list-disc ml-6 text-sm text-blue-700 space-y-1">
                        <li>This is a <strong>regularized version</strong> of the original problem $\min_x f_i(x)$</li>
                        <li>The quadratic penalty pulls $x$ toward the "target" $z^k - u_i^k$</li>
                        <li>As $\rho$ increases, the penalty becomes stronger, forcing closer consensus</li>
                        <li>Each agent can solve this <strong>independently</strong> in parallel</li>
                    </ul>
                </div>

                <div class="grid md:grid-cols-2 gap-4 mt-6">
                    <div class="bg-white border border-slate-200 rounded-lg p-4">
                        <h5 class="font-semibold mb-2">Example: Linear Regression</h5>
                        <p class="text-xs text-slate-600 mb-2">If $f_i(x) = \frac{1}{2}\|A_i x - b_i\|_2^2$:</p>
                        <div class="math-nowrap text-xs">
                            $x_i^{k+1} = (A_i^T A_i + \rho I)^{-1}(A_i^T b_i + \rho(z^k - u_i^k))$
                        </div>
                        <p class="text-xs text-slate-600 mt-2">Closed form solution!</p>
                    </div>

                    <div class="bg-white border border-slate-200 rounded-lg p-4">
                        <h5 class="font-semibold mb-2">Example: Logistic Regression</h5>
                        <p class="text-xs text-slate-600 mb-2">If $f_i(x) = \sum_j \log(1 + \exp(-y_j x^T a_j))$:</p>
                        <p class="text-xs text-slate-600">Use L-BFGS or gradient descent with the modified objective
                            including the quadratic penalty term.</p>
                    </div>
                </div>
            </div>

            <div class="step">
                <div class="flex items-center gap-3 mb-4">
                    <span class="step-number">3</span>
                    <h3 class="text-xl font-semibold">The Global Subproblem (z-update)</h3>
                </div>
                <p class="text-slate-700 mb-3">The consensus variable update is:</p>
                <div class="math-nowrap">
                    $z^{k+1} = \text{prox}_{g/(K\rho)} \left( \frac{1}{K}\sum_{i=1}^K (x_i^{k+1} + u_i^k) \right)$
                </div>

                <div class="bg-green-50 p-4 rounded-lg mt-4">
                    <h4 class="font-semibold text-green-800 mb-2">Step-by-step breakdown:</h4>
                    <ol class="list-decimal ml-6 text-sm text-green-700 space-y-2">
                        <li><strong>Collect:</strong> Gather $x_i^{k+1} + u_i^k$ from all agents</li>
                        <li><strong>Average:</strong> Compute $\bar{v} = \frac{1}{K}\sum_{i=1}^K (x_i^{k+1} + u_i^k)$
                        </li>
                        <li><strong>Apply prox:</strong> $z^{k+1} = \text{prox}_{g/(K\rho)}(\bar{v})$</li>
                    </ol>
                </div>

                <div class="grid md:grid-cols-2 gap-4 mt-6">
                    <div class="bg-white border border-slate-200 rounded-lg p-4">
                        <h5 class="font-semibold mb-2">Special Case: $g \equiv 0$</h5>
                        <p class="text-xs text-slate-600 mb-2">When there's no global regularization:</p>
                        <div class="math-nowrap text-xs">
                            $z^{k+1} = \frac{1}{K}\sum_{i=1}^K (x_i^{k+1} + u_i^k)$
                        </div>
                        <p class="text-xs text-slate-600 mt-2">Just simple averaging!</p>
                    </div>

                    <div class="bg-white border border-slate-200 rounded-lg p-4">
                        <h5 class="font-semibold mb-2">Example: Global $\ell_1$ Regularization</h5>
                        <p class="text-xs text-slate-600 mb-2">If $g(z) = \lambda\|z\|_1$:</p>
                        <div class="math-nowrap text-xs">
                            $z^{k+1} = \text{sign}(\bar{v}) \max\left(|\bar{v}| - \frac{\lambda}{K\rho}, 0\right)$
                        </div>
                        <p class="text-xs text-slate-600 mt-2">Soft-thresholding the average</p>
                    </div>
                </div>
            </div>

            <div class="step">
                <div class="flex items-center gap-3 mb-4">
                    <span class="step-number">4</span>
                    <h3 class="text-xl font-semibold">The Dual Update (u-update)</h3>
                </div>
                <p class="text-slate-700 mb-3">Update the scaled dual variables:</p>
                <div class="math-nowrap">
                    $u_i^{k+1} = u_i^k + (x_i^{k+1} - z^{k+1})$
                </div>

                <div class="insight text-sm mt-4">
                    <strong>Intuitive explanation:</strong>
                    <ul class="list-disc ml-6 mt-2 space-y-1">
                        <li>If $x_i^{k+1} > z^{k+1}$: agent $i$ wants to be "above" consensus, so increase $u_i$</li>
                        <li>If $x_i^{k+1} < z^{k+1}$: agent $i$ wants to be "below" consensus, so decrease $u_i$</li>
                        <li>The dual variables $u_i$ remember the "disagreement history" of each agent</li>
                        <li>This creates a feedback mechanism that drives consensus over time</li>
                    </ul>
                </div>
            </div>
        </div>
    </section>

    <!-- ======= Section: Practical Implementation ======= -->
    <section id="practical" class="py-12 bg-slate-50">
        <div class="max-w-7xl mx-auto px-6">
            <h2 class="text-3xl font-bold text-center mb-8">Practical Implementation Guide</h2>

            <div class="step">
                <div class="flex items-center gap-3 mb-4">
                    <span class="step-number">1</span>
                    <h3 class="text-xl font-semibold">Choosing the Penalty Parameter ρ</h3>
                </div>
                <div class="grid md:grid-cols-2 gap-6">
                    <div class="bg-white border border-slate-200 rounded-lg p-4">
                        <h4 class="font-semibold mb-3">Static Choice</h4>
                        <ul class="list-disc ml-6 text-sm text-slate-700 space-y-2">
                            <li><strong>Start with:</strong> $\rho = 1$ or $\rho = \|A\|_2^2$</li>
                            <li><strong>Scale by data:</strong> Use the scale of your objective function</li>
                            <li><strong>Grid search:</strong> Try $\rho \in \{0.1, 1, 10, 100\}$</li>
                        </ul>
                    </div>

                    <div class="bg-white border border-slate-200 rounded-lg p-4">
                        <h4 class="font-semibold mb-3">Adaptive Strategy</h4>
                        <div class="math-nowrap text-sm">
                            $\rho^{k+1} = \begin{cases}
                            \tau \rho^k & \text{if } \|r^k\|_2 > \mu \|s^k\|_2 \\
                            \rho^k / \tau & \text{if } \|s^k\|_2 > \mu \|r^k\|_2 \\
                            \rho^k & \text{otherwise}
                            \end{cases}$
                        </div>
                        <p class="text-xs text-slate-600 mt-2">Typical: $\mu = 10$, $\tau = 2$</p>
                    </div>
                </div>

                <div class="warn text-sm mt-4">
                    <strong>Important:</strong> When you change $\rho$, you must rescale the dual variables: $u_i
                    \leftarrow u_i \cdot (\rho_{\text{old}} / \rho_{\text{new}})$
                </div>
            </div>

            <div class="step">
                <div class="flex items-center gap-3 mb-4">
                    <span class="step-number">2</span>
                    <h3 class="text-xl font-semibold">Stopping Criteria</h3>
                </div>
                <p class="text-slate-700 mb-4">Monitor convergence using primal and dual residuals:</p>

                <div class="grid md:grid-cols-2 gap-4">
                    <div class="bg-red-50 p-4 rounded-lg">
                        <h4 class="font-semibold text-red-800 mb-2">Primal Residual</h4>
                        <div class="math-nowrap text-sm">
                            $r^k = \begin{bmatrix} x_1^k - z^k \\ \vdots \\ x_K^k - z^k \end{bmatrix}$
                        </div>
                        <p class="text-xs text-red-700 mt-2">Measures constraint violation (how far from consensus)</p>
                    </div>

                    <div class="bg-orange-50 p-4 rounded-lg">
                        <h4 class="font-semibold text-orange-800 mb-2">Dual Residual</h4>
                        <div class="math-nowrap text-sm">
                            $s^k = \rho(z^k - z^{k-1})$
                        </div>
                        <p class="text-xs text-orange-700 mt-2">Measures dual feasibility (how much consensus changed)
                        </p>
                    </div>
                </div>

                <div class="bg-gray-50 p-4 rounded-lg mt-4">
                    <h4 class="font-semibold mb-2">Practical Tolerances</h4>
                    <div class="math-nowrap text-sm">
                        $\begin{aligned}
                        \varepsilon_{\text{pri}} &= \sqrt{Kn} \varepsilon_{\text{abs}} + \varepsilon_{\text{rel}}
                        \max\{\|x^k\|_2, \sqrt{K}\|z^k\|_2\} \\
                        \varepsilon_{\text{dual}} &= \sqrt{Kn} \varepsilon_{\text{abs}} + \varepsilon_{\text{rel}} \rho
                        \|\sum_i u_i^k\|_2
                        \end{aligned}$
                    </div>
                    <p class="text-xs text-slate-600 mt-2">Typical: $\varepsilon_{\text{abs}} = 10^{-4}$,
                        $\varepsilon_{\text{rel}} = 10^{-2}$</p>
                </div>
            </div>

            <div class="step">
                <div class="flex items-center gap-3 mb-4">
                    <span class="step-number">3</span>
                    <h3 class="text-xl font-semibold">Over-relaxation (Advanced)</h3>
                </div>
                <p class="text-slate-700 mb-3">Sometimes convergence can be accelerated using over-relaxation with
                    parameter $\alpha \in [1, 1.8]$:</p>
                <div class="math-nowrap">
                    $\tilde{x}_i^{k+1} = \alpha x_i^{k+1} + (1-\alpha) z^k$
                </div>
                <p class="text-slate-700 mt-3">Then use $\tilde{x}_i^{k+1}$ instead of $x_i^{k+1}$ in the $z$-update:
                </p>
                <div class="math-nowrap">
                    $z^{k+1} = \text{prox}_{g/(K\rho)} \left( \frac{1}{K}\sum_{i=1}^K (\tilde{x}_i^{k+1} + u_i^k)
                    \right)$
                </div>
                <div class="insight text-sm mt-4">
                    <strong>When to use:</strong> Over-relaxation often helps on ill-conditioned problems or when
                    convergence is slow. Start with $\alpha = 1.5$.
                </div>
            </div>

            <div class="step">
                <div class="flex items-center gap-3 mb-4">
                    <span class="step-number">4</span>
                    <h3 class="text-xl font-semibold">Common Implementation Pitfalls</h3>
                </div>
                <div class="grid md:grid-cols-2 gap-6">
                    <div class="warn text-sm">
                        <strong>Numerical Issues:</strong>
                        <ul class="list-disc ml-6 mt-2 space-y-1">
                            <li>Always check for NaN/Inf after each update</li>
                            <li>Scale your data to have reasonable magnitudes</li>
                            <li>Start with small $\rho$ and increase gradually</li>
                            <li>Use double precision when possible</li>
                        </ul>
                    </div>

                    <div class="warn text-sm">
                        <strong>Convergence Issues:</strong>
                        <ul class="list-disc ml-6 mt-2 space-y-1">
                            <li>If primal residual decreases but dual increases: reduce $\rho$</li>
                            <li>If dual residual decreases but primal increases: increase $\rho$</li>
                            <li>Monitor the objective function value</li>
                            <li>Don't solve subproblems too accurately initially</li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- ======= Section: Complete Example ======= -->
    <section id="example" class="py-12">
        <div class="max-w-7xl mx-auto px-6">
            <h2 class="text-3xl font-bold text-center mb-8">Complete Example: Federated Ridge Regression</h2>

            <div class="bg-white border border-slate-200 rounded-2xl p-6 shadow card">
                <h3 class="text-xl font-semibold mb-4">Problem Setup</h3>
                <p class="text-slate-700 mb-3">Suppose $K$ hospitals want to jointly train a ridge regression model
                    without sharing patient data:</p>
                <div class="math-nowrap">
                    $\min_{\{x_i\}, z} \sum_{i=1}^K \left[ \frac{1}{2}\|A_i x_i - b_i\|_2^2 \right] +
                    \frac{\lambda}{2}\|z\|_2^2 \quad \text{s.t.} \quad x_i = z$
                </div>
                <p class="text-slate-700 mt-3">Each hospital $i$ has data $(A_i, b_i)$ and wants to find a common model
                    $z$.</p>

                <div class="bg-gray-50 p-6 rounded-lg mt-6">
                    <h4 class="font-semibold mb-4">ADMM Updates</h4>
                    <div class="grid md:grid-cols-3 gap-4 text-sm">
                        <div class="bg-blue-50 p-4 rounded">
                            <h5 class="font-semibold text-blue-800 mb-2">1. Local Update (each hospital)</h5>
                            <div class="math-nowrap text-xs">
                                $x_i^{k+1} = (A_i^T A_i + \rho I)^{-1}(A_i^T b_i + \rho(z^k - u_i^k))$
                            </div>
                            <p class="text-xs text-blue-700 mt-2">Solve ridge regression with penalty toward consensus
                            </p>
                        </div>

                        <div class="bg-green-50 p-4 rounded">
                            <h5 class="font-semibold text-green-800 mb-2">2. Global Update (server)</h5>
                            <div class="math-nowrap text-xs">
                                $z^{k+1} = \frac{1}{1 + \lambda/(K\rho)} \cdot \frac{1}{K}\sum_{i=1}^K (x_i^{k+1} +
                                u_i^k)$
                            </div>
                            <p class="text-xs text-green-700 mt-2">Ridge-regularized average</p>
                        </div>

                        <div class="bg-purple-50 p-4 rounded">
                            <h5 class="font-semibold text-purple-800 mb-2">3. Dual Update</h5>
                            <div class="math-nowrap text-xs">
                                $u_i^{k+1} = u_i^k + (x_i^{k+1} - z^{k+1})$
                            </div>
                            <p class="text-xs text-purple-700 mt-2">Track disagreement</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- ======= Section: Pseudocode ======= -->
    <section id="pseudo" class="py-12 bg-slate-50">
        <div class="max-w-7xl mx-auto px-6">
            <h2 class="text-3xl font-bold text-center mb-8">Complete Pseudocode</h2>
            <div class="bg-white border border-slate-200 rounded-2xl p-6 shadow card">
                <pre class="text-sm leading-6 overflow-x-auto"><code><span class="text-green-600">// Consensus ADMM for min Σᵢ fᵢ(xᵢ) + g(z) s.t. xᵢ = z</span>

<span class="text-blue-600">function</span> <span class="font-semibold">consensus_admm</span>(f, g, K, ρ, max_iter, tol):
    <span class="text-green-600">// Initialize variables</span>
    z ← 0                          <span class="text-gray-500">// consensus variable</span>
    xᵢ ← 0 for i = 1,...,K          <span class="text-gray-500">// local variables</span>
    uᵢ ← 0 for i = 1,...,K          <span class="text-gray-500">// scaled dual variables</span>
    
    <span class="text-blue-600">for</span> k = 0, 1, 2, ..., max_iter:
        
        <span class="text-green-600">// 1. LOCAL UPDATES (parallel across agents)</span>
        <span class="text-blue-600">for</span> i = 1 to K <span class="text-blue-600">in parallel</span>:
            target = z - uᵢ           <span class="text-gray-500">// current target for agent i</span>
            xᵢ ← argmin_x [fᵢ(x) + (ρ/2)||x - target||²]
        
        <span class="text-green-600">// 2. GLOBAL UPDATE (at server/coordinator)</span>
        x_avg ← (1/K) Σᵢ xᵢ           <span class="text-gray-500">// average local solutions</span>
        u_avg ← (1/K) Σᵢ uᵢ           <span class="text-gray-500">// average dual variables</span>
        v ← x_avg + u_avg            <span class="text-gray-500">// input to proximal operator</span>
        z ← prox_{g/(Kρ)}(v)         <span class="text-gray-500">// apply global regularization</span>
        
        <span class="text-green-600">// 3. DUAL UPDATES</span>
        <span class="text-blue-600">for</span> i = 1 to K:
            uᵢ ← uᵢ + (xᵢ - z)        <span class="text-gray-500">// track disagreement</span>
        
        <span class="text-green-600">// 4. CONVERGENCE CHECK</span>
        r ← [x₁ - z; x₂ - z; ...; xₖ - z]     <span class="text-gray-500">// primal residual</span>
        s ← ρ(z - z_prev)                      <span class="text-gray-500">// dual residual</span>
        
        <span class="text-blue-600">if</span> ||r||₂ ≤ ε_pri <span class="text-blue-600">and</span> ||s||₂ ≤ ε_dual:
            <span class="text-blue-600">break</span>                           <span class="text-gray-500">// converged!</span>
        
        <span class="text-green-600">// 5. ADAPTIVE ρ (optional)</span>
        <span class="text-blue-600">if</span> ||r||₂ > μ||s||₂:               <span class="text-gray-500">// primal large, dual small</span>
            ρ ← τ * ρ                          <span class="text-gray-500">// increase penalty</span>
            uᵢ ← uᵢ / τ for all i              <span class="text-gray-500">// rescale duals</span>
        <span class="text-blue-600">elif</span> ||s||₂ > μ||r||₂:             <span class="text-gray-500">// dual large, primal small</span>
            ρ ← ρ / τ                          <span class="text-gray-500">// decrease penalty</span>
            uᵢ ← uᵢ * τ for all i              <span class="text-gray-500">// rescale duals</span>
        
        z_prev ← z                            <span class="text-gray-500">// save for next iteration</span>
    
    <span class="text-blue-600">return</span> z, {xᵢ}                           <span class="text-gray-500">// consensus solution</span>

<span class="text-green-600">// Typical parameters: μ = 10, τ = 2, ε_pri = ε_dual = 1e-3</span></code></pre>
            </div>
        </div>
    </section>

    <section id="pseudo" class="py-12 bg-slate-50">
        <div class="max-w-7xl mx-auto px-6">
            <h2 class="text-3xl font-bold text-center mb-8">Clasroom Framework</h2>
            <div class="bg-white border border-slate-200 rounded-2xl p-6 shadow card">
                <img src="federated_admm_diagram.svg">
    </section>

    <!-- ================== USAGE BLOCK: FederatedConsensusADMM ================== -->
    <section id="framework-usage" class="py-14 bg-white">
        <div class="max-w-7xl mx-auto px-6">
            <header class="mb-8">
                <h2 class="text-3xl md:text-4xl font-extrabold tracking-tight text-slate-900">Using the Framework —
                    <span class="text-indigo-600">in 5 Minutes</span></h2>
                <p class="mt-2 text-slate-700 max-w-3xl">This block shows how to subclass
                    <code>FederatedConsensusADMM</code>, run a federated optimization, read the logs, and customize
                    advanced options. It is designed to be a <b>drop‑in section</b> for the documentation site you’re
                    building.</p>
            </header>

            <!-- Quick Start Cards -->
            <div class="grid md:grid-cols-3 gap-4">
                <div class="border border-slate-200 rounded-xl p-4 bg-slate-50">
                    <div class="text-slate-500 text-xs font-semibold">STEP 1</div>
                    <h3 class="font-semibold">Subclass</h3>
                    <p class="text-sm text-slate-700">Implement the three required hooks: <code>_init_blocks</code>,
                        <code>_local_update</code>, <code>_objective</code>.</p>
                </div>
                <div class="border border-slate-200 rounded-xl p-4 bg-slate-50">
                    <div class="text-slate-500 text-xs font-semibold">STEP 2</div>
                    <h3 class="font-semibold">Fit</h3>
                    <p class="text-sm text-slate-700">Call <code>fit(X_list, y_list)</code>. The framework runs ADMM
                        with residual checks, adaptive ρ, and timing.</p>
                </div>
                <div class="border border-slate-200 rounded-xl p-4 bg-slate-50">
                    <div class="text-slate-500 text-xs font-semibold">STEP 3</div>
                    <h3 class="font-semibold">Inspect</h3>
                    <p class="text-sm text-slate-700">Read <code>history_</code>, <code>z_</code>,
                        <code>x_local_</code>, and <code>u_</code>. Plot convergence and compare to centralized
                        baselines.</p>
                </div>
            </div>

            <!-- Minimal Example: Federated Ridge Regression -->
            <div class="mt-10">
                <h3 class="text-2xl font-bold mb-3">Minimal Example — Federated Ridge Regression</h3>
                <p class="text-slate-700">We solve
                    <span class="math-nowrap">$$\min_{\{x_i\},\,z} \sum_{i=1}^K \tfrac12\|A_i x_i - b_i\|_2^2 +
                        \tfrac{\lambda}{2}\|z\|_2^2 \quad \text{s.t. } x_i=z\;.$$</span>
                </p>

                <div class="relative">
                    <button
                        class="copy-btn absolute right-2 top-2 text-xs px-2 py-1 rounded-md bg-slate-800 text-white">Copy</button>
                    <pre class="text-sm leading-6 overflow-x-auto p-4 rounded-lg border border-slate-200 bg-slate-50"><code class="language-python">from __future__ import annotations
import numpy as np
from typing import Dict, List, Optional, Sequence

# Assume FederatedConsensusADMM is already imported

class FedRidge(FederatedConsensusADMM):
    def __init__(self, lam: float = 1e-1, **kw):
        super().__init__(**kw)
        self.lam = float(lam)

    # ---- required hooks ----
    def _init_blocks(self, X_list, y_list) -> Dict[str, np.ndarray]:
        n_features = X_list[0].shape[1]
        return {"w": np.zeros((n_features,), dtype=float)}

    def _local_update(self, i: int, z_minus_u: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:
        A_i = self._X[i]; b_i = self._y[i]; zmu = z_minus_u["w"]
        # Closed form: (AᵢᵀAᵢ + ρ I)⁻¹ (Aᵢᵀbᵢ + ρ zmu)
        rho = self._rho_for_block("w")
        G = A_i.T @ A_i + rho * np.eye(A_i.shape[1])
        rhs = A_i.T @ b_i + rho * zmu
        w_i = np.linalg.solve(G, rhs)
        return {"w": w_i}

    def _objective(self, X_list, y_list, x_locals: List[Dict[str, np.ndarray]]) -> float:
        # monitoring objective (separable local loss + global ridge on z)
        loss = 0.0
        for i, d in enumerate(x_locals):
            w_i = d["w"]; A_i = self._X[i]; b_i = self._y[i]
            r = A_i @ w_i - b_i
            loss += 0.5 * float(r @ r)
        loss += 0.5 * self.lam * float(self.z_["w"] @ self.z_["w"])  # ridge on consensus
        return loss

    # ---- optional: global prox for ridge ----
    def _prox(self, name: str, v: np.ndarray) -> np.ndarray:
        if name == "w":
            # z^{k+1} = argmin_z (λ/2)||z||² + (Kρ/2)||z - v||²
            K = len(self._X)
            return (K * self.rho) / (K * self.rho + self.lam) * v
        return v

    # small helper so hooks can see data
    def fit(self, X_list: Sequence[np.ndarray], y_list: Sequence[np.ndarray], **kw):
        self._X = X_list; self._y = y_list
        return super().fit(X_list, y_list, **kw)


# ----- toy run -----
np.random.seed(0)
K = 4
X_list = []
y_list = []
true_w = np.array([1.5, -2.0, 0.7])
for _ in range(K):
    A = np.random.randn(200, 3)
    y = A @ true_w + 0.1 * np.random.randn(200)
    X_list.append(A); y_list.append(y)

solver = FedRidge(lam=0.5, rho=1.0, max_iters=200, adaptive_rho=True, over_relaxation=1.2,
                  verbose=True, parallel_mode="threading", max_workers=4)
solver.fit(X_list, y_list)

print("Consensus w:", solver.z_["w"].round(3))
print("Converged?", solver.history_.converged, "in", solver.history_.iters, "iters")</code></pre>
                </div>

                <p class="text-xs text-slate-500 mt-2">Tip: set <code>verbose=True</code> to print per‑iteration
                    diagnostics (r, s, ρ, obj). For plotting, see the next snippet.</p>
            </div>

            <!-- Reading History & Plotting -->
            <div class="mt-10">
                <h3 class="text-2xl font-bold mb-3">Inspecting Convergence &amp; Timing</h3>
                <p class="text-slate-700">The class records residuals, tolerances, objective, ρ, and timing information
                    into <code>history_</code>:</p>
                <div class="relative">
                    <button
                        class="copy-btn absolute right-2 top-2 text-xs px-2 py-1 rounded-md bg-slate-800 text-white">Copy</button>
                    <pre class="text-sm leading-6 overflow-x-auto p-4 rounded-lg border border-slate-200 bg-slate-50"><code class="language-python">import matplotlib.pyplot as plt
H = solver.history_

plt.figure()
plt.semilogy(H.r_norm, label="‖r‖₂ (primal)")
plt.semilogy(H.s_norm, label="‖s‖₂ (dual)")
plt.semilogy(H.eps_pri, "--", label="ε_pri")
plt.semilogy(H.eps_dual, "--", label="ε_dual")
plt.legend(); plt.xlabel("iteration"); plt.ylabel("value"); plt.title("ADMM Residuals"); plt.show()

print("reason:", H.reason)
print("avg local step time:", np.mean(H.timing["local_updates"]))
print("avg global step time:", np.mean(H.timing["global_updates"]))</code></pre>
                </div>
            </div>

            <!-- API Cheatsheet -->
            <div class="mt-12">
                <h3 class="text-2xl font-bold mb-3">API Cheatsheet</h3>
                <div class="grid md:grid-cols-2 gap-6">
                    <div class="border border-slate-200 rounded-xl p-4">
                        <h4 class="font-semibold mb-2">Override these hooks</h4>
                        <ul class="list-disc ml-6 text-sm text-slate-700 space-y-1">
                            <li><code>_init_blocks(X_list, y_list) → Dict[str, np.ndarray]</code>: define consensus
                                blocks and shapes.</li>
                            <li><code>_local_update(i, z_minus_u)</code>: solve site‑<em>i</em> proximalized problem for
                                all blocks.</li>
                            <li><code>_objective(X_list, y_list, x_locals)</code>: monitoring objective (used for
                                logs/early‑stop).</li>
                        </ul>
                        <h4 class="font-semibold mt-4 mb-2">Optional customization</h4>
                        <ul class="list-disc ml-6 text-sm text-slate-700 space-y-1">
                            <li><code>_prox(name, v)</code>: global prox per block (e.g., ℓ₁ / ℓ₂ regularization,
                                constraints).</li>
                            <li><code>_prox_arg_scale(name)</code>, <code>_rho_for_block(name)</code>: scaling /
                                block‑wise ρ.</li>
                            <li><code>snapshot()</code> / <code>restore()</code>, checkpointing, robust aggregation
                                methods.</li>
                        </ul>
                    </div>
                    <div class="border border-slate-200 rounded-xl p-4">
                        <h4 class="font-semibold mb-2">Constructor highlights</h4>
                        <ul class="list-disc ml-6 text-sm text-slate-700 space-y-1">
                            <li><code>rho, max_iters, abstol, reltol</code></li>
                            <li><code>adaptive_rho=True, rho_mu=10, rho_tau=2</code></li>
                            <li><code>over_relaxation=1.0…1.8</code> (α); try 1.2–1.6 for tough cases</li>
                            <li><code>parallel_mode</code>: <code>"none"</code>, <code>"threading"</code>, or
                                <code>"multiprocessing"</code></li>
                            <li><code>aggregation_method</code>: <code>weighted_avg</code> | <code>median</code> |
                                <code>trimmed_mean</code></li>
                            <li><code>communication_rounds</code>, <code>compression_ratio</code> (bandwidth trade‑offs)
                            </li>
                            <li><code>patience</code>, <code>min_improvement</code>, <code>convergence_window</code>
                                (early stop)</li>
                        </ul>
                    </div>
                </div>
            </div>

            <!-- Math: Updates Recap (Scaled Form) -->
            <div class="mt-12">
                <h3 class="text-2xl font-bold mb-3">What the Solver Executes (Scaled ADMM)</h3>
                <div class="grid md:grid-cols-3 gap-4 text-sm">
                    <div class="bg-blue-50 p-4 rounded-lg">
                        <strong>x‑update:</strong>
                        <div class="math-nowrap">$$x_i^{k+1} = \arg\min_x\; f_i(x) + \tfrac{\rho}{2}\|x - z^k +
                            u_i^k\|_2^2$$</div>
                    </div>
                    <div class="bg-green-50 p-4 rounded-lg">
                        <strong>z‑update:</strong>
                        <div class="math-nowrap">$$z^{k+1} = \operatorname{prox}_{g/(K\rho)}\!\left(\tfrac{1}{K}\sum_i
                            (x_i^{k+1}+u_i^k)\right)$$</div>
                    </div>
                    <div class="bg-purple-50 p-4 rounded-lg">
                        <strong>u‑update:</strong>
                        <div class="math-nowrap">$$u_i^{k+1} = u_i^k + (x_i^{k+1} - z^{k+1})$$</div>
                    </div>
                </div>
            </div>

            <!-- Common Pitfalls -->
            <div class="mt-12">
                <h3 class="text-2xl font-bold mb-3">Common Pitfalls &amp; Remedies</h3>
                <div class="grid md:grid-cols-2 gap-6 text-sm">
                    <div class="bg-amber-50 border border-amber-200 rounded-lg p-4">
                        <strong>Residuals oscillate:</strong>
                        <ul class="list-disc ml-6 mt-2 space-y-1">
                            <li>Enable <code>adaptive_rho</code>; increase <code>rho_tau</code> slightly (e.g., 2 → 3).
                            </li>
                            <li>Use <code>over_relaxation≈1.4</code>; standard trick for ill‑conditioned problems.</li>
                            <li>Standardize features; scale objectives to similar magnitudes.</li>
                        </ul>
                    </div>
                    <div class="bg-red-50 border border-red-200 rounded-lg p-4">
                        <strong>NaN/Inf appears:</strong>
                        <ul class="list-disc ml-6 mt-2 space-y-1">
                            <li>Check data for NaNs; regularize local solves (<code>+ εI</code>).</li>
                            <li>Gradually grow <code>rho</code> instead of starting large.</li>
                            <li>Verify shapes match across blocks/sites.</li>
                        </ul>
                    </div>
                </div>
            </div>

            <!-- FAQ mini -->
            <div class="mt-12">
                <h3 class="text-2xl font-bold mb-3">FAQ</h3>
                <div class="space-y-3 text-sm text-slate-700">
                    <details class="p-3 border border-slate-200 rounded-lg bg-slate-50">
                        <summary class="font-semibold cursor-pointer">Is ADMM exact for k‑means / nonconvex models?
                        </summary>
                        <div class="pt-2">No. For nonconvex problems, ADMM is a heuristic with strong empirical
                            performance, but convergence to global minima isn’t guaranteed. For convex problems (ridge,
                            LASSO, constrained LS), you have standard convergence guarantees.</div>
                    </details>
                    <details class="p-3 border border-slate-200 rounded-lg bg-slate-50">
                        <summary class="font-semibold cursor-pointer">When should I use over‑relaxation?</summary>
                        <div class="pt-2">When the primal residual decays slowly or oscillates. Try α∈[1.2,1.6]; α=1
                            recovers vanilla ADMM.</div>
                    </details>
                    <details class="p-3 border border-slate-200 rounded-lg bg-slate-50">
                        <summary class="font-semibold cursor-pointer">Do I need exact local solves?</summary>
                        <div class="pt-2">Not necessarily. A few iterations of an inner method (e.g., CG/L‑BFGS) often
                            suffice; exactness isn’t required for convergence in practice.</div>
                    </details>
                </div>
            </div>
        </div>
    </section>

    <script>
        // Simple copy-to-clipboard for the code blocks in this section
        (function () {
            const blocks = document.querySelectorAll('#framework-usage .copy-btn');
            blocks.forEach(btn => {
                btn.addEventListener('click', () => {
                    const pre = btn.nextElementSibling;
                    const code = pre && pre.querySelector('code');
                    if (!code) return;
                    const text = code.innerText;
                    navigator.clipboard.writeText(text).then(() => {
                        const old = btn.textContent; btn.textContent = 'Copied!';
                        setTimeout(() => btn.textContent = old, 1200);
                    });
                });
            });
        })();
    </script>
    <!-- Prism.js code highlighting (auto-injected if not present) -->
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/prismjs@1/themes/prism.min.css" as="style"
        onload="this.onload=null;this.rel='stylesheet'">
    <noscript>
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@1/themes/prism.min.css">
    </noscript>
    <!-- Prism CSS -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs/themes/prism.min.css">

    <!-- Prism core + languages -->
    <script src="https://cdn.jsdelivr.net/npm/prismjs/prism.min.js" defer></script>
    <script src="https://cdn.jsdelivr.net/npm/prismjs/components/prism-python.min.js" defer></script>
    <script src="https://cdn.jsdelivr.net/npm/prismjs/components/prism-javascript.min.js" defer></script>
    <script src="https://cdn.jsdelivr.net/npm/prismjs/components/prism-bash.min.js" defer></script>

    <!-- Line numbers plugin (optional) -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs/plugins/line-numbers/prism-line-numbers.css">
    <script src="https://cdn.jsdelivr.net/npm/prismjs/plugins/line-numbers/prism-line-numbers.min.js" defer></script>

    <script>
        document.addEventListener("DOMContentLoaded", function () {
            function waitForPrism() {
                if (window.Prism && Prism.highlightAllUnder) {
                    const root = document.querySelector('#framework-usage');
                    if (root) {
                        root.querySelectorAll('pre').forEach(pre => pre.classList.add('line-numbers'));
                        Prism.highlightAllUnder(root);
                    }
                } else {
                    setTimeout(waitForPrism, 100); // retry until Prism is ready
                }
            }
            waitForPrism();
        });
    </script>

    <script>(function () {
            function add(tag, attrs) { var el = document.createElement(tag); for (var k in attrs) el[k] = attrs[k]; (document.head || document.documentElement).appendChild(el); return el; }
            if (!window.Prism) { add('script', { src: 'https://cdn.jsdelivr.net/npm/prismjs@1/components/prism-core.min.js', defer: true }); }
            ['markup', 'javascript', 'python', 'bash'].forEach(function (l) { add('script', { src: 'https://cdn.jsdelivr.net/npm/prismjs@1/components/prism-' + l + '.min.js', defer: true }); });
            add('script', { src: 'https://cdn.jsdelivr.net/npm/prismjs@1/plugins/line-numbers/prism-line-numbers.min.js', defer: true });
            add('link', { rel: 'preload', href: 'https://cdn.jsdelivr.net/npm/prismjs@1/plugins/line-numbers/prism-line-numbers.css', as: 'style', onload: "this.onload=null;this.rel='stylesheet'" });
            document.addEventListener('DOMContentLoaded', function () {
                var root = document.querySelector('#framework-usage'); if (!root) return;
                root.querySelectorAll('pre').forEach(function (pre) { pre.classList.add('line-numbers'); });
                if (window.Prism && Prism.highlightAllUnder) { Prism.highlightAllUnder(root); }
                setTimeout(function () { if (window.Prism && Prism.highlightAllUnder) { Prism.highlightAllUnder(root); } }, 300);
            });
        })();</script>

    <!-- ================== /USAGE BLOCK ================== -->

    <!-- ======= Footer ======= -->
    <footer class="py-10 bg-slate-900 text-slate-200">
        <div class="max-w-7xl mx-auto px-6">
            <div class="flex flex-col md:flex-row items-center justify-between gap-4">
                <p class="text-sm">© <span id="year"></span> ADMM Explained — Pedagogical Guide to Distributed
                    Optimization</p>
                <div class="text-xs text-slate-400">Step-by-step • Intuitive • Practical</div>
            </div>
            <div class="mt-4 pt-4 border-t border-slate-700 text-center text-xs text-slate-400">
                From motivation to implementation • Understanding consensus • Proximal operators • Real-world examples
            </div>
        </div>
        </div>
        </div>
    </footer>

    <script>
        document.addEventListener('DOMContentLoaded', () => {
            const y = document.getElementById('year'); if (y) y.textContent = new Date().getFullYear();
            document.querySelectorAll('a[href^="#"]').forEach(a => {
                a.addEventListener('click', (e) => { e.preventDefault(); const t = document.querySelector(a.getAttribute('href')); if (t) t.scrollIntoView({ behavior: 'smooth', block: 'start' }); });
            });
        });
    </script>

</body>

</html>